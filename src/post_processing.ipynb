{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Spelling and correcting grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:18<00:00, 13.3MB/s] \n",
      "Unzipping /var/folders/ry/pyw8c_113gv5wnpxnq6tw6380000gn/T/tmppp89879e.zip to /Users/javier/.cache/language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /Users/javier/.cache/language_tool_python.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata = {\\n    \\'premise\\': [\"This is an example premise.\"],\\n    \\'hypothesis\\': [\"This is a hypothesis.\"],\\n    \\'machine_explanation\\': [\"This is teh explanation for the premise and hypothesis.\"],\\n    \\'label\\': [\\'entailment\\']\\n}\\n\\ndf = pd.DataFrame(data)\\ndf_spelling = df.copy()\\ndf_spelling[\\'corrected_explanation\\'] = df_spelling[\\'machine_explanation\\'].apply(correct_text)\\ndf_spelling.head()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import language_tool_python\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Initialize the language tool for English and spellchecker\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_text(text):\n",
    "    # Correct grammar using language_tool_python\n",
    "    matches = tool.check(text)\n",
    "    corrected_text = tool.correct(text)\n",
    "\n",
    "    # Correct spelling using pyspellchecker\n",
    "    words = corrected_text.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    for word in misspelled:\n",
    "        corrected_word = spell.correction(word)\n",
    "        # Only replace if a correction is found\n",
    "        if corrected_word:\n",
    "            corrected_text = corrected_text.replace(word, corrected_word, 1)\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "# Example usage with a DataFrame\n",
    "'''\n",
    "data = {\n",
    "    'premise': [\"This is an example premise.\"],\n",
    "    'hypothesis': [\"This is a hypothesis.\"],\n",
    "    'machine_explanation': [\"This is teh explanation for the premise and hypothesis.\"],\n",
    "    'label': ['entailment']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_spelling = df.copy()\n",
    "df_spelling['corrected_explanation'] = df_spelling['machine_explanation'].apply(correct_text)\n",
    "df_spelling.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Semantic Consistency Checking\n",
    "\n",
    "Ensure that the generated explanation actually corresponds semantically with the premise and hypothesis. This can be done using similarity metrics like cosine similarity on sentence embeddings. Tools like Sentence-BERT can be utilized to convert sentences to embeddings and then compute their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def check_semantic_similarity(text1, text2):\n",
    "    \"\"\"Calculate semantic similarity between two texts.\"\"\"\n",
    "    embeddings1 = sbert_model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = sbert_model.encode(text2, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return similarity.item()\n",
    "\n",
    "def process_explanations(row):\n",
    "    \"\"\"Process each row of the DataFrame.\"\"\"\n",
    "    premise = row['premise']\n",
    "    hypothesis = row['hypothesis']\n",
    "    explanation = row['machine_explanation']\n",
    "\n",
    "    # Combine premise and hypothesis for a full context comparison\n",
    "    full_context = premise + \" \" + hypothesis\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarity_score = check_semantic_similarity(explanation, full_context)\n",
    "\n",
    "    return pd.Series({\n",
    "        'similarity_score': similarity_score,\n",
    "        'processed_explanation': explanation  # Placeholder for any additional processing\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Redundancy removal\n",
    "\n",
    "Detect and remove repeated phrases or sentences to make the text more concise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "# calculate edit distance between sentences\n",
    "def edit_distance(s1, s2):\n",
    "    s1 = [word.lower() for word in word_tokenize(s1)]\n",
    "    s2 = [word.lower() for word in word_tokenize(s2)]\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "    dp = [[0 for x in range(n+1)] for x in range(m+1)]\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif s1[i-1] == s2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i][j-1] + 1,        # Insert\n",
    "                            dp[i-1][j] + 1,        # Remove\n",
    "                            dp[i-1][j-1] + 2)      # Replace\n",
    "    return dp[m][n]\n",
    "\n",
    "count = 0\n",
    "def remove_redundancy(text, max_edit_distance):\n",
    "    sentences = sent_tokenize(text)\n",
    "    n = len(sentences)\n",
    "    new_sentence = []\n",
    "    for i in range(n):\n",
    "        if i == n - 1:\n",
    "            new_sentence.append(sentences[i]) # add last sentence (already compared with previous sentence last iteration)\n",
    "            break\n",
    "\n",
    "        if edit_distance(sentences[i], sentences[i+1]) < max_edit_distance:\n",
    "            global count\n",
    "            count += 1\n",
    "            # print(text)\n",
    "            continue\n",
    "\n",
    "        new_sentence.append(sentences[i])\n",
    "\n",
    "    return \" \".join(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from safetensors.torch import load_model, save_model\n",
    "\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "def renameColumns(df):\n",
    "    return df.rename(columns={'Sentence1': 'premise', 'Sentence2': 'hypothesis', 'Explanation_1': 'explanation'})\n",
    "\n",
    "def filterNan(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def convert_to_tensors(df):\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "def encode_labels(df):\n",
    "    return df.apply(lambda x: int(label_to_id[x]))\n",
    "\n",
    "template = \"Given that {}, it is hypothesized that {}. {}.\"\n",
    "\n",
    "def tokenize(df, tokenizer):\n",
    "    tokenized_batch = []\n",
    "    for _, row in df.iterrows():\n",
    "        premise = row['premise'].lower()\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        hypothesis = row['hypothesis'].lower()\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        explanation = row['explanation'].lower()\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text = template.format(premise, hypothesis, explanation),\n",
    "            padding=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        tokenized_batch.append(encoded_dict)\n",
    "    return tokenized_batch\n",
    "\n",
    "def calc_f1_score(predicted_classes, actual_labels):\n",
    "    return f1_score(predicted_classes, actual_labels, average='weighted'), f1_score(predicted_classes, actual_labels, average='micro'), f1_score(predicted_classes, actual_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_template = 'Given that {}, it is hypothesized that {}.'\n",
    "explanation_template = 'This is {} because {}.'\n",
    "\n",
    "class eSNLIDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, train=True):\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx,:]\n",
    "        premise = example[\"premise\"]\n",
    "        hypothesis = example[\"hypothesis\"]\n",
    "        explanation = example[\"explanation\"]\n",
    "\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "        premise = premise_template.format(premise, hypothesis)\n",
    "        explanation = explanation_template.format(self.tokenizer.mask_token, explanation)\n",
    "\n",
    "        if self.train:\n",
    "            label = example[\"gold_label\"]\n",
    "            return premise, explanation, label\n",
    "\n",
    "        return premise, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/raw/gpt_output.csv\")\n",
    "df_test_renamed = renameColumns(df_test)\n",
    "df_test_cleaned = filterNan(df_test_renamed)\n",
    "df_test_cleaned.loc[:, \"gold_label\"] = encode_labels(df_test_cleaned[\"gold_label\"])\n",
    "df_test_final = df_test_cleaned.loc[:, [\"gold_label\", \"premise\", \"hypothesis\", \"machine_explanation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>machine_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>A boy flips a burger.</td>\n",
       "      <td>An older man in a coffee shop and a boy flippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>An elderly man sits in a small shop.</td>\n",
       "      <td>The detailed setting of a coffee shop and othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>Some women are hugging on vacation.</td>\n",
       "      <td>The specifics of the women being blond and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>The women are sleeping.</td>\n",
       "      <td>Women hugging and women sleeping are mutually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>There are women showing affection.</td>\n",
       "      <td>Women showing affection directly supports the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2</td>\n",
       "      <td>Asian students wearing blazers sit at differen...</td>\n",
       "      <td>Libriarians are shelving books.</td>\n",
       "      <td>Asian students studying and librarians shelvin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are walking some place</td>\n",
       "      <td>Standing behind a barrier and walking are dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are standing outside</td>\n",
       "      <td>Standing outside encompasses various scenarios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of dogs are running</td>\n",
       "      <td>A group of people and a group of dogs describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>Two women in skirts stand together behind a me...</td>\n",
       "      <td>A woman wearing a skirt stands all alone by th...</td>\n",
       "      <td>Two women standing together and one woman alon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gold_label                                            premise  \\\n",
       "0            2  An older man sits with his orange juice at a s...   \n",
       "1            1  An older man sits with his orange juice at a s...   \n",
       "2            1           Two blond women are hugging one another.   \n",
       "3            2           Two blond women are hugging one another.   \n",
       "4            0           Two blond women are hugging one another.   \n",
       "..         ...                                                ...   \n",
       "435          2  Asian students wearing blazers sit at differen...   \n",
       "436          1  A group of people are standing on sidewalk beh...   \n",
       "437          0  A group of people are standing on sidewalk beh...   \n",
       "438          2  A group of people are standing on sidewalk beh...   \n",
       "439          2  Two women in skirts stand together behind a me...   \n",
       "\n",
       "                                            hypothesis  \\\n",
       "0                                A boy flips a burger.   \n",
       "1                 An elderly man sits in a small shop.   \n",
       "2                  Some women are hugging on vacation.   \n",
       "3                              The women are sleeping.   \n",
       "4                   There are women showing affection.   \n",
       "..                                                 ...   \n",
       "435                    Libriarians are shelving books.   \n",
       "436           A group of people are walking some place   \n",
       "437             A group of people are standing outside   \n",
       "438                        A group of dogs are running   \n",
       "439  A woman wearing a skirt stands all alone by th...   \n",
       "\n",
       "                                   machine_explanation  \n",
       "0    An older man in a coffee shop and a boy flippi...  \n",
       "1    The detailed setting of a coffee shop and othe...  \n",
       "2    The specifics of the women being blond and the...  \n",
       "3    Women hugging and women sleeping are mutually ...  \n",
       "4    Women showing affection directly supports the ...  \n",
       "..                                                 ...  \n",
       "435  Asian students studying and librarians shelvin...  \n",
       "436  Standing behind a barrier and walking are dist...  \n",
       "437  Standing outside encompasses various scenarios...  \n",
       "438  A group of people and a group of dogs describe...  \n",
       "439  Two women standing together and one woman alon...  \n",
       "\n",
       "[440 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "\n",
    "# change the model's classifier to a smaller one\n",
    "dense = nn.Linear(768, 256)\n",
    "out = nn.Linear(256, 3)\n",
    "model.classifier.dense = dense\n",
    "model.classifier.out_proj = out\n",
    "\n",
    "# freeze all the parameters in the base model\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only train the classification head\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model(model, \"model.safetensors\")\n",
    "\n",
    "# predict after training\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test without Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_no_pp = df_test_final.copy()\n",
    "df_test_no_pp.rename(columns={'machine_explanation': 'explanation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_no_pp, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.50      0.71      0.59       174\n",
      "      neutral       0.35      0.19      0.25       162\n",
      "contradiction       0.56      0.57      0.56       164\n",
      "\n",
      "     accuracy                           0.49       500\n",
      "    macro avg       0.47      0.49      0.47       500\n",
      " weighted avg       0.47      0.49      0.47       500\n",
      "\n",
      "(0.519018764804707, 0.494, 0.4656819021936371)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell checking and grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_spelling = df_test_final.copy()\n",
    "df_test_spelling['explanation'] = df_test_spelling['machine_explanation'].apply(correct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_spelling, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.42      0.07      0.13       175\n",
      "      neutral       0.32      0.82      0.46       158\n",
      "contradiction       0.41      0.16      0.23       163\n",
      "\n",
      "     accuracy                           0.34       496\n",
      "    macro avg       0.38      0.35      0.27       496\n",
      " weighted avg       0.38      0.34      0.27       496\n",
      "\n",
      "(0.41058535763646825, 0.3387096774193548, 0.27227564787977093)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_spelling.to_csv(\"../data/v2/PP/output_gen_test(0-500)_spelling.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic similarity checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_semantics = df_test_final.copy()\n",
    "df_test_semantics.loc[:, ['similarity_score', 'processed_explanation']] = df_test_semantics.apply(process_explanations, axis=1)\n",
    "df_test_semantics.rename(columns={'processed_explanation': 'explanation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_semantics, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>machine_explanation</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>A boy flips a burger.</td>\n",
       "      <td>An older man in a coffee shop and a boy flippi...</td>\n",
       "      <td>0.440353</td>\n",
       "      <td>An older man in a coffee shop and a boy flippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>An elderly man sits in a small shop.</td>\n",
       "      <td>The detailed setting of a coffee shop and othe...</td>\n",
       "      <td>0.430189</td>\n",
       "      <td>The detailed setting of a coffee shop and othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>Some women are hugging on vacation.</td>\n",
       "      <td>The specifics of the women being blond and the...</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>The specifics of the women being blond and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>The women are sleeping.</td>\n",
       "      <td>Women hugging and women sleeping are mutually ...</td>\n",
       "      <td>0.587220</td>\n",
       "      <td>Women hugging and women sleeping are mutually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>There are women showing affection.</td>\n",
       "      <td>Women showing affection directly supports the ...</td>\n",
       "      <td>0.748105</td>\n",
       "      <td>Women showing affection directly supports the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2</td>\n",
       "      <td>Asian students wearing blazers sit at differen...</td>\n",
       "      <td>Libriarians are shelving books.</td>\n",
       "      <td>Asian students studying and librarians shelvin...</td>\n",
       "      <td>0.630914</td>\n",
       "      <td>Asian students studying and librarians shelvin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are walking some place</td>\n",
       "      <td>Standing behind a barrier and walking are dist...</td>\n",
       "      <td>0.548094</td>\n",
       "      <td>Standing behind a barrier and walking are dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are standing outside</td>\n",
       "      <td>Standing outside encompasses various scenarios...</td>\n",
       "      <td>0.529034</td>\n",
       "      <td>Standing outside encompasses various scenarios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of dogs are running</td>\n",
       "      <td>A group of people and a group of dogs describe...</td>\n",
       "      <td>0.315518</td>\n",
       "      <td>A group of people and a group of dogs describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>Two women in skirts stand together behind a me...</td>\n",
       "      <td>A woman wearing a skirt stands all alone by th...</td>\n",
       "      <td>Two women standing together and one woman alon...</td>\n",
       "      <td>0.432561</td>\n",
       "      <td>Two women standing together and one woman alon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gold_label                                            premise  \\\n",
       "0            2  An older man sits with his orange juice at a s...   \n",
       "1            1  An older man sits with his orange juice at a s...   \n",
       "2            1           Two blond women are hugging one another.   \n",
       "3            2           Two blond women are hugging one another.   \n",
       "4            0           Two blond women are hugging one another.   \n",
       "..         ...                                                ...   \n",
       "435          2  Asian students wearing blazers sit at differen...   \n",
       "436          1  A group of people are standing on sidewalk beh...   \n",
       "437          0  A group of people are standing on sidewalk beh...   \n",
       "438          2  A group of people are standing on sidewalk beh...   \n",
       "439          2  Two women in skirts stand together behind a me...   \n",
       "\n",
       "                                            hypothesis  \\\n",
       "0                                A boy flips a burger.   \n",
       "1                 An elderly man sits in a small shop.   \n",
       "2                  Some women are hugging on vacation.   \n",
       "3                              The women are sleeping.   \n",
       "4                   There are women showing affection.   \n",
       "..                                                 ...   \n",
       "435                    Libriarians are shelving books.   \n",
       "436           A group of people are walking some place   \n",
       "437             A group of people are standing outside   \n",
       "438                        A group of dogs are running   \n",
       "439  A woman wearing a skirt stands all alone by th...   \n",
       "\n",
       "                                   machine_explanation  similarity_score  \\\n",
       "0    An older man in a coffee shop and a boy flippi...          0.440353   \n",
       "1    The detailed setting of a coffee shop and othe...          0.430189   \n",
       "2    The specifics of the women being blond and the...          0.694433   \n",
       "3    Women hugging and women sleeping are mutually ...          0.587220   \n",
       "4    Women showing affection directly supports the ...          0.748105   \n",
       "..                                                 ...               ...   \n",
       "435  Asian students studying and librarians shelvin...          0.630914   \n",
       "436  Standing behind a barrier and walking are dist...          0.548094   \n",
       "437  Standing outside encompasses various scenarios...          0.529034   \n",
       "438  A group of people and a group of dogs describe...          0.315518   \n",
       "439  Two women standing together and one woman alon...          0.432561   \n",
       "\n",
       "                                           explanation  \n",
       "0    An older man in a coffee shop and a boy flippi...  \n",
       "1    The detailed setting of a coffee shop and othe...  \n",
       "2    The specifics of the women being blond and the...  \n",
       "3    Women hugging and women sleeping are mutually ...  \n",
       "4    Women showing affection directly supports the ...  \n",
       "..                                                 ...  \n",
       "435  Asian students studying and librarians shelvin...  \n",
       "436  Standing behind a barrier and walking are dist...  \n",
       "437  Standing outside encompasses various scenarios...  \n",
       "438  A group of people and a group of dogs describe...  \n",
       "439  Two women standing together and one woman alon...  \n",
       "\n",
       "[440 rows x 6 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.92      0.92      0.92       146\n",
      "      neutral       0.78      0.96      0.86       148\n",
      "contradiction       0.96      0.73      0.83       146\n",
      "\n",
      "     accuracy                           0.87       440\n",
      "    macro avg       0.88      0.87      0.87       440\n",
      " weighted avg       0.88      0.87      0.87       440\n",
      "\n",
      "(0.8716580178102378, 0.8704545454545455, 0.8692905480417427)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_semantics.to_csv(\"../data/gpt4/gpt_output_semantics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundancy removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_redundant = df_test_final.copy()\n",
    "df_test_redundant[\"explanation\"] = df_test_redundant[\"machine_explanation\"].apply(lambda x: remove_redundancy(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_redundant, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.40      0.10      0.16       175\n",
      "      neutral       0.32      0.68      0.43       158\n",
      "contradiction       0.40      0.28      0.33       163\n",
      "\n",
      "     accuracy                           0.34       496\n",
      "    macro avg       0.37      0.35      0.31       496\n",
      " weighted avg       0.37      0.34      0.30       496\n",
      "\n",
      "(0.3830362674581212, 0.34274193548387094, 0.30716419730504235)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_redundant.to_csv(\"../data/v2/PP/output_gen_test(0-500)_redundant.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
