{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading LanguageTool 6.4: 100%|██████████| 246M/246M [00:18<00:00, 13.3MB/s] \n",
      "Unzipping /var/folders/ry/pyw8c_113gv5wnpxnq6tw6380000gn/T/tmppp89879e.zip to /Users/javier/.cache/language_tool_python.\n",
      "Downloaded https://www.languagetool.org/download/LanguageTool-6.4.zip to /Users/javier/.cache/language_tool_python.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata = {\\n    \\'premise\\': [\"This is an example premise.\"],\\n    \\'hypothesis\\': [\"This is a hypothesis.\"],\\n    \\'machine_explanation\\': [\"This is teh explanation for the premise and hypothesis.\"],\\n    \\'label\\': [\\'entailment\\']\\n}\\n\\ndf = pd.DataFrame(data)\\ndf_spelling = df.copy()\\ndf_spelling[\\'corrected_explanation\\'] = df_spelling[\\'machine_explanation\\'].apply(correct_text)\\ndf_spelling.head()\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import language_tool_python\n",
    "import pandas as pd\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "# Initialize the language tool for English and spellchecker\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "spell = SpellChecker()\n",
    "\n",
    "def correct_text(text):\n",
    "    # Correct grammar using language_tool_python\n",
    "    matches = tool.check(text)\n",
    "    corrected_text = tool.correct(text)\n",
    "\n",
    "    # Correct spelling using pyspellchecker\n",
    "    words = corrected_text.split()\n",
    "    misspelled = spell.unknown(words)\n",
    "    for word in misspelled:\n",
    "        corrected_word = spell.correction(word)\n",
    "        # Only replace if a correction is found\n",
    "        if corrected_word:\n",
    "            corrected_text = corrected_text.replace(word, corrected_word, 1)\n",
    "\n",
    "    return corrected_text\n",
    "\n",
    "# Example usage with a DataFrame\n",
    "'''\n",
    "data = {\n",
    "    'premise': [\"This is an example premise.\"],\n",
    "    'hypothesis': [\"This is a hypothesis.\"],\n",
    "    'machine_explanation': [\"This is teh explanation for the premise and hypothesis.\"],\n",
    "    'label': ['entailment']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df_spelling = df.copy()\n",
    "df_spelling['corrected_explanation'] = df_spelling['machine_explanation'].apply(correct_text)\n",
    "df_spelling.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def check_semantic_similarity(text1, text2):\n",
    "    \"\"\"Calculate semantic similarity between two texts.\"\"\"\n",
    "    embeddings1 = sbert_model.encode(text1, convert_to_tensor=True)\n",
    "    embeddings2 = sbert_model.encode(text2, convert_to_tensor=True)\n",
    "    similarity = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "    return similarity.item()\n",
    "\n",
    "def process_explanations(row):\n",
    "    \"\"\"Process each row of the DataFrame.\"\"\"\n",
    "    premise = row['premise']\n",
    "    hypothesis = row['hypothesis']\n",
    "    explanation = row['machine_explanation']\n",
    "\n",
    "    # Combine premise and hypothesis for a full context comparison\n",
    "    full_context = premise + \" \" + hypothesis\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarity_score = check_semantic_similarity(explanation, full_context)\n",
    "\n",
    "    return pd.Series({\n",
    "        'similarity_score': similarity_score,\n",
    "        'processed_explanation': explanation  # Placeholder for any additional processing\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "\n",
    "# calculate edit distance between sentences\n",
    "def edit_distance(s1, s2):\n",
    "    s1 = [word.lower() for word in word_tokenize(s1)]\n",
    "    s2 = [word.lower() for word in word_tokenize(s2)]\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "    dp = [[0 for x in range(n+1)] for x in range(m+1)]\n",
    "    for i in range(m+1):\n",
    "        for j in range(n+1):\n",
    "            if i == 0:\n",
    "                dp[i][j] = j\n",
    "            elif j == 0:\n",
    "                dp[i][j] = i\n",
    "            elif s1[i-1] == s2[j-1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = min(dp[i][j-1] + 1,        # Insert\n",
    "                            dp[i-1][j] + 1,        # Remove\n",
    "                            dp[i-1][j-1] + 2)      # Replace\n",
    "    return dp[m][n]\n",
    "\n",
    "count = 0\n",
    "def remove_redundancy(text, max_edit_distance):\n",
    "    sentences = sent_tokenize(text)\n",
    "    n = len(sentences)\n",
    "    new_sentence = []\n",
    "    for i in range(n):\n",
    "        if i == n - 1:\n",
    "            new_sentence.append(sentences[i]) # add last sentence (already compared with previous sentence last iteration)\n",
    "            break\n",
    "\n",
    "        if edit_distance(sentences[i], sentences[i+1]) < max_edit_distance:\n",
    "            global count\n",
    "            count += 1\n",
    "            # print(text)\n",
    "            continue\n",
    "\n",
    "        new_sentence.append(sentences[i])\n",
    "\n",
    "    return \" \".join(new_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from safetensors.torch import load_model, save_model\n",
    "\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "def renameColumns(df):\n",
    "    return df.rename(columns={'Sentence1': 'premise', 'Sentence2': 'hypothesis', 'Explanation_1': 'explanation'})\n",
    "\n",
    "def filterNan(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def convert_to_tensors(df):\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "def encode_labels(df):\n",
    "    return df.apply(lambda x: int(label_to_id[x]))\n",
    "\n",
    "template = \"Given that {}, it is hypothesized that {}. {}.\"\n",
    "\n",
    "def tokenize(df, tokenizer):\n",
    "    tokenized_batch = []\n",
    "    for _, row in df.iterrows():\n",
    "        premise = row['premise'].lower()\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        hypothesis = row['hypothesis'].lower()\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        explanation = row['explanation'].lower()\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text = template.format(premise, hypothesis, explanation),\n",
    "            padding=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        tokenized_batch.append(encoded_dict)\n",
    "    return tokenized_batch\n",
    "\n",
    "def calc_f1_score(predicted_classes, actual_labels):\n",
    "    return f1_score(predicted_classes, actual_labels, average='weighted'), f1_score(predicted_classes, actual_labels, average='micro'), f1_score(predicted_classes, actual_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_template = 'Given that {}, it is hypothesized that {}.'\n",
    "explanation_template = 'This is {} because {}.'\n",
    "\n",
    "class eSNLIDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, train=True):\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx,:]\n",
    "        premise = example[\"premise\"]\n",
    "        hypothesis = example[\"hypothesis\"]\n",
    "        explanation = example[\"explanation\"]\n",
    "\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "        premise = premise_template.format(premise, hypothesis)\n",
    "        explanation = explanation_template.format(self.tokenizer.mask_token, explanation)\n",
    "\n",
    "        if self.train:\n",
    "            label = example[\"gold_label\"]\n",
    "            return premise, explanation, label\n",
    "\n",
    "        return premise, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/raw/gpt_output.csv\")\n",
    "df_test_renamed = renameColumns(df_test)\n",
    "df_test_cleaned = filterNan(df_test_renamed)\n",
    "df_test_cleaned.loc[:, \"gold_label\"] = encode_labels(df_test_cleaned[\"gold_label\"])\n",
    "df_test_final = df_test_cleaned.loc[:, [\"gold_label\", \"premise\", \"hypothesis\", \"machine_explanation\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>machine_explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>A boy flips a burger.</td>\n",
       "      <td>An older man in a coffee shop and a boy flippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>An elderly man sits in a small shop.</td>\n",
       "      <td>The detailed setting of a coffee shop and othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>Some women are hugging on vacation.</td>\n",
       "      <td>The specifics of the women being blond and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>The women are sleeping.</td>\n",
       "      <td>Women hugging and women sleeping are mutually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>There are women showing affection.</td>\n",
       "      <td>Women showing affection directly supports the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2</td>\n",
       "      <td>Asian students wearing blazers sit at differen...</td>\n",
       "      <td>Libriarians are shelving books.</td>\n",
       "      <td>Asian students studying and librarians shelvin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are walking some place</td>\n",
       "      <td>Standing behind a barrier and walking are dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are standing outside</td>\n",
       "      <td>Standing outside encompasses various scenarios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of dogs are running</td>\n",
       "      <td>A group of people and a group of dogs describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>Two women in skirts stand together behind a me...</td>\n",
       "      <td>A woman wearing a skirt stands all alone by th...</td>\n",
       "      <td>Two women standing together and one woman alon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gold_label                                            premise  \\\n",
       "0            2  An older man sits with his orange juice at a s...   \n",
       "1            1  An older man sits with his orange juice at a s...   \n",
       "2            1           Two blond women are hugging one another.   \n",
       "3            2           Two blond women are hugging one another.   \n",
       "4            0           Two blond women are hugging one another.   \n",
       "..         ...                                                ...   \n",
       "435          2  Asian students wearing blazers sit at differen...   \n",
       "436          1  A group of people are standing on sidewalk beh...   \n",
       "437          0  A group of people are standing on sidewalk beh...   \n",
       "438          2  A group of people are standing on sidewalk beh...   \n",
       "439          2  Two women in skirts stand together behind a me...   \n",
       "\n",
       "                                            hypothesis  \\\n",
       "0                                A boy flips a burger.   \n",
       "1                 An elderly man sits in a small shop.   \n",
       "2                  Some women are hugging on vacation.   \n",
       "3                              The women are sleeping.   \n",
       "4                   There are women showing affection.   \n",
       "..                                                 ...   \n",
       "435                    Libriarians are shelving books.   \n",
       "436           A group of people are walking some place   \n",
       "437             A group of people are standing outside   \n",
       "438                        A group of dogs are running   \n",
       "439  A woman wearing a skirt stands all alone by th...   \n",
       "\n",
       "                                   machine_explanation  \n",
       "0    An older man in a coffee shop and a boy flippi...  \n",
       "1    The detailed setting of a coffee shop and othe...  \n",
       "2    The specifics of the women being blond and the...  \n",
       "3    Women hugging and women sleeping are mutually ...  \n",
       "4    Women showing affection directly supports the ...  \n",
       "..                                                 ...  \n",
       "435  Asian students studying and librarians shelvin...  \n",
       "436  Standing behind a barrier and walking are dist...  \n",
       "437  Standing outside encompasses various scenarios...  \n",
       "438  A group of people and a group of dogs describe...  \n",
       "439  Two women standing together and one woman alon...  \n",
       "\n",
       "[440 rows x 4 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "\n",
    "# change the model's classifier to a smaller one\n",
    "dense = nn.Linear(768, 256)\n",
    "out = nn.Linear(256, 3)\n",
    "model.classifier.dense = dense\n",
    "model.classifier.out_proj = out\n",
    "\n",
    "# freeze all the parameters in the base model\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only train the classification head\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=256, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=256, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model(model, \"model.safetensors\")\n",
    "\n",
    "# predict after training\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test without PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_no_pp = df_test_final.copy()\n",
    "df_test_no_pp.rename(columns={'machine_explanation': 'explanation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_no_pp, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.50      0.71      0.59       174\n",
      "      neutral       0.35      0.19      0.25       162\n",
      "contradiction       0.56      0.57      0.56       164\n",
      "\n",
      "     accuracy                           0.49       500\n",
      "    macro avg       0.47      0.49      0.47       500\n",
      " weighted avg       0.47      0.49      0.47       500\n",
      "\n",
      "(0.519018764804707, 0.494, 0.4656819021936371)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell checking and grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_spelling = df_test_final.copy()\n",
    "df_test_spelling['explanation'] = df_test_spelling['machine_explanation'].apply(correct_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_spelling, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.42      0.07      0.13       175\n",
      "      neutral       0.32      0.82      0.46       158\n",
      "contradiction       0.41      0.16      0.23       163\n",
      "\n",
      "     accuracy                           0.34       496\n",
      "    macro avg       0.38      0.35      0.27       496\n",
      " weighted avg       0.38      0.34      0.27       496\n",
      "\n",
      "(0.41058535763646825, 0.3387096774193548, 0.27227564787977093)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_spelling.to_csv(\"../data/v2/PP/output_gen_test(0-500)_spelling.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic similarity checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_semantics = df_test_final.copy()\n",
    "df_test_semantics.loc[:, ['similarity_score', 'processed_explanation']] = df_test_semantics.apply(process_explanations, axis=1)\n",
    "df_test_semantics.rename(columns={'processed_explanation': 'explanation'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_semantics, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>machine_explanation</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>A boy flips a burger.</td>\n",
       "      <td>An older man in a coffee shop and a boy flippi...</td>\n",
       "      <td>0.440353</td>\n",
       "      <td>An older man in a coffee shop and a boy flippi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>An older man sits with his orange juice at a s...</td>\n",
       "      <td>An elderly man sits in a small shop.</td>\n",
       "      <td>The detailed setting of a coffee shop and othe...</td>\n",
       "      <td>0.430189</td>\n",
       "      <td>The detailed setting of a coffee shop and othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>Some women are hugging on vacation.</td>\n",
       "      <td>The specifics of the women being blond and the...</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>The specifics of the women being blond and the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>The women are sleeping.</td>\n",
       "      <td>Women hugging and women sleeping are mutually ...</td>\n",
       "      <td>0.587220</td>\n",
       "      <td>Women hugging and women sleeping are mutually ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Two blond women are hugging one another.</td>\n",
       "      <td>There are women showing affection.</td>\n",
       "      <td>Women showing affection directly supports the ...</td>\n",
       "      <td>0.748105</td>\n",
       "      <td>Women showing affection directly supports the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>2</td>\n",
       "      <td>Asian students wearing blazers sit at differen...</td>\n",
       "      <td>Libriarians are shelving books.</td>\n",
       "      <td>Asian students studying and librarians shelvin...</td>\n",
       "      <td>0.630914</td>\n",
       "      <td>Asian students studying and librarians shelvin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are walking some place</td>\n",
       "      <td>Standing behind a barrier and walking are dist...</td>\n",
       "      <td>0.548094</td>\n",
       "      <td>Standing behind a barrier and walking are dist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>0</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of people are standing outside</td>\n",
       "      <td>Standing outside encompasses various scenarios...</td>\n",
       "      <td>0.529034</td>\n",
       "      <td>Standing outside encompasses various scenarios...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2</td>\n",
       "      <td>A group of people are standing on sidewalk beh...</td>\n",
       "      <td>A group of dogs are running</td>\n",
       "      <td>A group of people and a group of dogs describe...</td>\n",
       "      <td>0.315518</td>\n",
       "      <td>A group of people and a group of dogs describe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>2</td>\n",
       "      <td>Two women in skirts stand together behind a me...</td>\n",
       "      <td>A woman wearing a skirt stands all alone by th...</td>\n",
       "      <td>Two women standing together and one woman alon...</td>\n",
       "      <td>0.432561</td>\n",
       "      <td>Two women standing together and one woman alon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    gold_label                                            premise  \\\n",
       "0            2  An older man sits with his orange juice at a s...   \n",
       "1            1  An older man sits with his orange juice at a s...   \n",
       "2            1           Two blond women are hugging one another.   \n",
       "3            2           Two blond women are hugging one another.   \n",
       "4            0           Two blond women are hugging one another.   \n",
       "..         ...                                                ...   \n",
       "435          2  Asian students wearing blazers sit at differen...   \n",
       "436          1  A group of people are standing on sidewalk beh...   \n",
       "437          0  A group of people are standing on sidewalk beh...   \n",
       "438          2  A group of people are standing on sidewalk beh...   \n",
       "439          2  Two women in skirts stand together behind a me...   \n",
       "\n",
       "                                            hypothesis  \\\n",
       "0                                A boy flips a burger.   \n",
       "1                 An elderly man sits in a small shop.   \n",
       "2                  Some women are hugging on vacation.   \n",
       "3                              The women are sleeping.   \n",
       "4                   There are women showing affection.   \n",
       "..                                                 ...   \n",
       "435                    Libriarians are shelving books.   \n",
       "436           A group of people are walking some place   \n",
       "437             A group of people are standing outside   \n",
       "438                        A group of dogs are running   \n",
       "439  A woman wearing a skirt stands all alone by th...   \n",
       "\n",
       "                                   machine_explanation  similarity_score  \\\n",
       "0    An older man in a coffee shop and a boy flippi...          0.440353   \n",
       "1    The detailed setting of a coffee shop and othe...          0.430189   \n",
       "2    The specifics of the women being blond and the...          0.694433   \n",
       "3    Women hugging and women sleeping are mutually ...          0.587220   \n",
       "4    Women showing affection directly supports the ...          0.748105   \n",
       "..                                                 ...               ...   \n",
       "435  Asian students studying and librarians shelvin...          0.630914   \n",
       "436  Standing behind a barrier and walking are dist...          0.548094   \n",
       "437  Standing outside encompasses various scenarios...          0.529034   \n",
       "438  A group of people and a group of dogs describe...          0.315518   \n",
       "439  Two women standing together and one woman alon...          0.432561   \n",
       "\n",
       "                                           explanation  \n",
       "0    An older man in a coffee shop and a boy flippi...  \n",
       "1    The detailed setting of a coffee shop and othe...  \n",
       "2    The specifics of the women being blond and the...  \n",
       "3    Women hugging and women sleeping are mutually ...  \n",
       "4    Women showing affection directly supports the ...  \n",
       "..                                                 ...  \n",
       "435  Asian students studying and librarians shelvin...  \n",
       "436  Standing behind a barrier and walking are dist...  \n",
       "437  Standing outside encompasses various scenarios...  \n",
       "438  A group of people and a group of dogs describe...  \n",
       "439  Two women standing together and one woman alon...  \n",
       "\n",
       "[440 rows x 6 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.92      0.92      0.92       146\n",
      "      neutral       0.78      0.96      0.86       148\n",
      "contradiction       0.96      0.73      0.83       146\n",
      "\n",
      "     accuracy                           0.87       440\n",
      "    macro avg       0.88      0.87      0.87       440\n",
      " weighted avg       0.88      0.87      0.87       440\n",
      "\n",
      "(0.8716580178102378, 0.8704545454545455, 0.8692905480417427)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_semantics.to_csv(\"../data/gpt4/gpt_output_semantics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redundancy removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_redundant = df_test_final.copy()\n",
    "df_test_redundant[\"explanation\"] = df_test_redundant[\"machine_explanation\"].apply(lambda x: remove_redundancy(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(df_test_redundant, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   entailment       0.40      0.10      0.16       175\n",
      "      neutral       0.32      0.68      0.43       158\n",
      "contradiction       0.40      0.28      0.33       163\n",
      "\n",
      "     accuracy                           0.34       496\n",
      "    macro avg       0.37      0.35      0.31       496\n",
      " weighted avg       0.37      0.34      0.30       496\n",
      "\n",
      "(0.3830362674581212, 0.34274193548387094, 0.30716419730504235)\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "actual_labels = df_test_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_redundant.to_csv(\"../data/v2/PP/output_gen_test(0-500)_redundant.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>machine_explanation</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>the church has cracks in the ceiling</td>\n",
       "      <td>the roof is falling down.The church was built...</td>\n",
       "      <td>0.464577</td>\n",
       "      <td>the roof is falling down.The church was built...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>the church is filled with song</td>\n",
       "      <td>the choir is singing joyously.The church has ...</td>\n",
       "      <td>0.762740</td>\n",
       "      <td>the choir is singing joyously.The church has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>a choir singing at a baseball game</td>\n",
       "      <td>the church is singing to a different choir.Th...</td>\n",
       "      <td>0.563366</td>\n",
       "      <td>the church is singing to a different choir.Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>a woman with a green headscarf blue shirt and ...</td>\n",
       "      <td>the woman is young</td>\n",
       "      <td>she is a girl.The woman in the picture is the...</td>\n",
       "      <td>0.314043</td>\n",
       "      <td>she is a girl.The woman in the picture is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>a woman with a green headscarf blue shirt and ...</td>\n",
       "      <td>the woman is very happy</td>\n",
       "      <td>she is a Muslim.The woman's face is covered b...</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>she is a Muslim.The woman's face is covered b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2</td>\n",
       "      <td>many children play in the water</td>\n",
       "      <td>the children are playing mini golf</td>\n",
       "      <td>they are not playing in a pool.The children's...</td>\n",
       "      <td>0.436987</td>\n",
       "      <td>they are not playing in a pool.The children's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2</td>\n",
       "      <td>a group of kids is splashing in deep water nea...</td>\n",
       "      <td>the kids are singing in a choir</td>\n",
       "      <td>they are not singing to the tune of the song....</td>\n",
       "      <td>0.457720</td>\n",
       "      <td>they are not singing to the tune of the song....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>a group of kids is splashing in deep water nea...</td>\n",
       "      <td>the kids are in deep water</td>\n",
       "      <td>they are swimming in the water.The kids were ...</td>\n",
       "      <td>0.450511</td>\n",
       "      <td>they are swimming in the water.The kids were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1</td>\n",
       "      <td>a group of kids is splashing in deep water nea...</td>\n",
       "      <td>they are wearing lifejackets</td>\n",
       "      <td>they have been swimming in the water for a lo...</td>\n",
       "      <td>0.532402</td>\n",
       "      <td>they have been swimming in the water for a lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2</td>\n",
       "      <td>a climber wearing a red headband is pulling hi...</td>\n",
       "      <td>a woman climber attempts to pull herself up</td>\n",
       "      <td>she is wearing red hairband.The woman climbin...</td>\n",
       "      <td>0.502188</td>\n",
       "      <td>she is wearing red hairband.The woman climbin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gold_label                                            premise  \\\n",
       "0             1  this church choir sings to the masses as they ...   \n",
       "1             0  this church choir sings to the masses as they ...   \n",
       "2             2  this church choir sings to the masses as they ...   \n",
       "3             1  a woman with a green headscarf blue shirt and ...   \n",
       "4             0  a woman with a green headscarf blue shirt and ...   \n",
       "..          ...                                                ...   \n",
       "495           2                    many children play in the water   \n",
       "496           2  a group of kids is splashing in deep water nea...   \n",
       "497           0  a group of kids is splashing in deep water nea...   \n",
       "498           1  a group of kids is splashing in deep water nea...   \n",
       "499           2  a climber wearing a red headband is pulling hi...   \n",
       "\n",
       "                                      hypothesis  \\\n",
       "0           the church has cracks in the ceiling   \n",
       "1                 the church is filled with song   \n",
       "2             a choir singing at a baseball game   \n",
       "3                             the woman is young   \n",
       "4                        the woman is very happy   \n",
       "..                                           ...   \n",
       "495           the children are playing mini golf   \n",
       "496              the kids are singing in a choir   \n",
       "497                   the kids are in deep water   \n",
       "498                 they are wearing lifejackets   \n",
       "499  a woman climber attempts to pull herself up   \n",
       "\n",
       "                                   machine_explanation  similarity_score  \\\n",
       "0     the roof is falling down.The church was built...          0.464577   \n",
       "1     the choir is singing joyously.The church has ...          0.762740   \n",
       "2     the church is singing to a different choir.Th...          0.563366   \n",
       "3     she is a girl.The woman in the picture is the...          0.314043   \n",
       "4     she is a Muslim.The woman's face is covered b...          0.389600   \n",
       "..                                                 ...               ...   \n",
       "495   they are not playing in a pool.The children's...          0.436987   \n",
       "496   they are not singing to the tune of the song....          0.457720   \n",
       "497   they are swimming in the water.The kids were ...          0.450511   \n",
       "498   they have been swimming in the water for a lo...          0.532402   \n",
       "499   she is wearing red hairband.The woman climbin...          0.502188   \n",
       "\n",
       "                                           explanation  \n",
       "0     the roof is falling down.The church was built...  \n",
       "1     the choir is singing joyously.The church has ...  \n",
       "2     the church is singing to a different choir.Th...  \n",
       "3     she is a girl.The woman in the picture is the...  \n",
       "4     she is a Muslim.The woman's face is covered b...  \n",
       "..                                                 ...  \n",
       "495   they are not playing in a pool.The children's...  \n",
       "496   they are not singing to the tune of the song....  \n",
       "497   they are swimming in the water.The kids were ...  \n",
       "498   they have been swimming in the water for a lo...  \n",
       "499   she is wearing red hairband.The woman climbin...  \n",
       "\n",
       "[500 rows x 6 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/v3/PP/output_gen_test(0-500)_semantics.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold_label</th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>machine_explanation</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0</td>\n",
       "      <td>a crowd of people looking up at 3 people on th...</td>\n",
       "      <td>the crowd on the ground is watching 3 people o...</td>\n",
       "      <td>the people in the building are looking down a...</td>\n",
       "      <td>0.876279</td>\n",
       "      <td>the people in the building are looking down a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1</td>\n",
       "      <td>a dog standing near snow looking at water</td>\n",
       "      <td>the dog is thinking about going to for a swim</td>\n",
       "      <td>of the snow.The dog's behavior is related wit...</td>\n",
       "      <td>0.774791</td>\n",
       "      <td>of the snow.The dog's behavior is related wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>this church choir sings to the masses as they ...</td>\n",
       "      <td>the church is filled with song</td>\n",
       "      <td>the choir is singing joyously.The church has ...</td>\n",
       "      <td>0.762740</td>\n",
       "      <td>the choir is singing joyously.The church has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "      <td>a woman is painting a mural of a woman's face</td>\n",
       "      <td>there is a woman painting for fun</td>\n",
       "      <td>she is doing it for her own enjoyment.The wom...</td>\n",
       "      <td>0.761445</td>\n",
       "      <td>she is doing it for her own enjoyment.The wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1</td>\n",
       "      <td>a group of people dancing together</td>\n",
       "      <td>they are doing the tango</td>\n",
       "      <td>they have a group.The tangos are not a dance....</td>\n",
       "      <td>0.761111</td>\n",
       "      <td>they have a group.The tangos are not a dance....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gold_label                                            premise  \\\n",
       "113           0  a crowd of people looking up at 3 people on th...   \n",
       "253           1          a dog standing near snow looking at water   \n",
       "1             0  this church choir sings to the masses as they ...   \n",
       "151           1      a woman is painting a mural of a woman's face   \n",
       "190           1                 a group of people dancing together   \n",
       "\n",
       "                                            hypothesis  \\\n",
       "113  the crowd on the ground is watching 3 people o...   \n",
       "253      the dog is thinking about going to for a swim   \n",
       "1                       the church is filled with song   \n",
       "151                  there is a woman painting for fun   \n",
       "190                           they are doing the tango   \n",
       "\n",
       "                                   machine_explanation  similarity_score  \\\n",
       "113   the people in the building are looking down a...          0.876279   \n",
       "253   of the snow.The dog's behavior is related wit...          0.774791   \n",
       "1     the choir is singing joyously.The church has ...          0.762740   \n",
       "151   she is doing it for her own enjoyment.The wom...          0.761445   \n",
       "190   they have a group.The tangos are not a dance....          0.761111   \n",
       "\n",
       "                                           explanation  \n",
       "113   the people in the building are looking down a...  \n",
       "253   of the snow.The dog's behavior is related wit...  \n",
       "1     the choir is singing joyously.The church has ...  \n",
       "151   she is doing it for her own enjoyment.The wom...  \n",
       "190   they have a group.The tangos are not a dance....  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get row with highest similarity score\n",
    "test_df = df.sort_values(by=\"similarity_score\", ascending=False).head()\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = eSNLIDataset(test_df, tokenizer, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 500]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m         predicted_classes \u001b[38;5;241m=\u001b[39m [pred\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m predicted_classes]\n\u001b[1;32m     16\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(predicted_classes)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactual_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabel_to_id\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(calc_f1_score(predictions, actual_labels))\n",
      "File \u001b[0;32m~/miniforge3/envs/cs4248/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/cs4248/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2604\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2469\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   2470\u001b[0m     {\n\u001b[1;32m   2471\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2495\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2496\u001b[0m ):\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2498\u001b[0m \n\u001b[1;32m   2499\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2601\u001b[0m \u001b[38;5;124;03m    <BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2602\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2604\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m         labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/miniforge3/envs/cs4248/lib/python3.10/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/cs4248/lib/python3.10/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 500]"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "actual_labels = test_df['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_dataset:\n",
    "        premise, hypothesis = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "print(classification_report(actual_labels, predictions, target_names=list(label_to_id.keys())))\n",
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_with_pred = pd.concat((test_df, pd.Series(predictions, name=\"predicted_label\")), axis=1)\n",
    "test_df_with_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
