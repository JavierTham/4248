{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairID</th>\n",
       "      <th>gold_label</th>\n",
       "      <th>Sentence1</th>\n",
       "      <th>Sentence2</th>\n",
       "      <th>Explanation_1</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>Sentence1_marked_1</th>\n",
       "      <th>Sentence2_marked_1</th>\n",
       "      <th>Sentence1_Highlighted_1</th>\n",
       "      <th>Sentence2_Highlighted_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3416050480.jpg#4r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is training his horse for a competition.</td>\n",
       "      <td>the person is not necessarily training his horse</td>\n",
       "      <td>AF0PI3RISB5Q7</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is *training* *his* *horse* for a co...</td>\n",
       "      <td>{}</td>\n",
       "      <td>3,4,5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3416050480.jpg#4r1c</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>One cannot be on a jumping horse cannot be a d...</td>\n",
       "      <td>A36ZT2WFIA2HMF</td>\n",
       "      <td>A person *on* *a* *horse* *jumps* over a brok...</td>\n",
       "      <td>A person *is* *at* *a* *diner,* *ordering* an...</td>\n",
       "      <td>4,2,3,5</td>\n",
       "      <td>2,5,4,3,6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3416050480.jpg#4r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>a broken down airplane is outdoors</td>\n",
       "      <td>A2GK75ZQTX2RDZ</td>\n",
       "      <td>A person on a horse jumps over *a* *broken* *...</td>\n",
       "      <td>A person is *outdoors,* on a horse.</td>\n",
       "      <td>8,9,10,7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2267923837.jpg#2r1n</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>Just because they are smiling and waving at a ...</td>\n",
       "      <td>A18TOIDG32QICP</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>They are smiling *at* *their* *parents*</td>\n",
       "      <td>{}</td>\n",
       "      <td>5,3,4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2267923837.jpg#2r1e</td>\n",
       "      <td>entailment</td>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>The children must be present to see them smili...</td>\n",
       "      <td>AEX0YE6TUZRHT</td>\n",
       "      <td>*Children* *smiling* *and* *waving* at camera</td>\n",
       "      <td>There are children *present*</td>\n",
       "      <td>0,1,3,2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pairID     gold_label  \\\n",
       "0  3416050480.jpg#4r1n        neutral   \n",
       "1  3416050480.jpg#4r1c  contradiction   \n",
       "2  3416050480.jpg#4r1e     entailment   \n",
       "3  2267923837.jpg#2r1n        neutral   \n",
       "4  2267923837.jpg#2r1e     entailment   \n",
       "\n",
       "                                           Sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2  A person on a horse jumps over a broken down a...   \n",
       "3              Children smiling and waving at camera   \n",
       "4              Children smiling and waving at camera   \n",
       "\n",
       "                                           Sentence2  \\\n",
       "0  A person is training his horse for a competition.   \n",
       "1      A person is at a diner, ordering an omelette.   \n",
       "2                  A person is outdoors, on a horse.   \n",
       "3                  They are smiling at their parents   \n",
       "4                         There are children present   \n",
       "\n",
       "                                       Explanation_1        WorkerId  \\\n",
       "0   the person is not necessarily training his horse   AF0PI3RISB5Q7   \n",
       "1  One cannot be on a jumping horse cannot be a d...  A36ZT2WFIA2HMF   \n",
       "2                 a broken down airplane is outdoors  A2GK75ZQTX2RDZ   \n",
       "3  Just because they are smiling and waving at a ...  A18TOIDG32QICP   \n",
       "4  The children must be present to see them smili...   AEX0YE6TUZRHT   \n",
       "\n",
       "                                  Sentence1_marked_1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1   A person *on* *a* *horse* *jumps* over a brok...   \n",
       "2   A person on a horse jumps over *a* *broken* *...   \n",
       "3              Children smiling and waving at camera   \n",
       "4      *Children* *smiling* *and* *waving* at camera   \n",
       "\n",
       "                                  Sentence2_marked_1 Sentence1_Highlighted_1  \\\n",
       "0   A person is *training* *his* *horse* for a co...                      {}   \n",
       "1   A person *is* *at* *a* *diner,* *ordering* an...                 4,2,3,5   \n",
       "2                A person is *outdoors,* on a horse.                8,9,10,7   \n",
       "3            They are smiling *at* *their* *parents*                      {}   \n",
       "4                       There are children *present*                 0,1,3,2   \n",
       "\n",
       "  Sentence2_Highlighted_1  \n",
       "0                   3,4,5  \n",
       "1               2,5,4,3,6  \n",
       "2                       3  \n",
       "3                   5,3,4  \n",
       "4                       3  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/esnli_train_1.csv') #rmb to train on whole dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renameColumnsTrain(df):\n",
    "    return df.rename(columns={'Sentence1': 'premise', 'Sentence2': 'hypothesis', 'Explanation_1': 'explanation'}).drop([\"WorkerId\", \"Sentence1_Highlighted_1\", \"Sentence2_Highlighted_1\"], axis=1)\n",
    "\n",
    "df_cleaned = renameColumnsTrain(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   250,   621,    15,    10,  5253, 13855,    81,    10,  3187,\n",
      "           159, 16847,     4,     2,     2,   250,   621,    16,  1058,    39,\n",
      "          5253,    13,    10,  1465,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1]])}\n",
      "Premise: A person on a horse jumps over a broken down airplane.\n",
      "Hypothesis: A person is training his horse for a competition.\n",
      "Explanation: the person is not necessarily training his horse\n",
      "\n",
      "True class: neutral\n",
      "Predicted class: neutral\n"
     ]
    }
   ],
   "source": [
    "# cell for testing the model's output for a single example\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
    "\n",
    "# Tokenize input\n",
    "premise = df_cleaned['premise'][0]\n",
    "hypothesis = df_cleaned['hypothesis'][0]\n",
    "explanation = df_cleaned['explanation'][0]\n",
    "actual_label = df_cleaned['gold_label'][0]\n",
    "encoded_input = tokenizer.encode_plus(premise, hypothesis, explanation, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "labels = torch.tensor(df_cleaned['gold_label'].replace(label_to_id).tolist())[0]\n",
    "print(encoded_input)\n",
    "output = model(**encoded_input)\n",
    "\n",
    "predicted_class = torch.argmax(output.logits, dim=1)\n",
    "\n",
    "print(f\"Premise: {premise}\\nHypothesis: {hypothesis}\\nExplanation: {explanation}\\n\")\n",
    "print(f\"True class: {actual_label}\")\n",
    "print(f\"Predicted class: {id_to_label[predicted_class.item()]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoBERTa classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterNan(df):\n",
    "    return df.dropna()\n",
    "\n",
    "# def tokenize(df):\n",
    "#     return df.apply(lambda x: tokenizer.encode_plus(x['premise'], x['hypothesis'], x['explanation'], padding='max_length', return_tensors='pt'), axis=1)\n",
    "\n",
    "def convert_to_tensors(df):\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "def encode_labels(df):\n",
    "    return df.apply(lambda x: label_to_id[x])\n",
    "\n",
    "template = \"Given that {}, it is hypothesized that {}. {}.\"\n",
    "\n",
    "def tokenize(df):\n",
    "    tokenized_batch = []\n",
    "    for _, row in df.iterrows():\n",
    "        premise = row['premise'].lower()\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        hypothesis = row['hypothesis'].lower()\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        explanation = row['explanation'].lower()\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text = template.format(premise, hypothesis, explanation),\n",
    "            # row['premise'], # two ways to encode\n",
    "            # row['hypothesis'], \n",
    "            # row['explanation'],\n",
    "            padding=True,\n",
    "            return_tensors='pt',\n",
    "            # truncation=True\n",
    "        )\n",
    "        tokenized_batch.append(encoded_dict)\n",
    "    return tokenized_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[RoBERTA huggingface](https://huggingface.co/FacebookAI/roberta-base#:~:text=RoBERTa%20is%20a%20transformers%20model%20pretrained%20on%20a,to%20generate%20inputs%20and%20labels%20from%20those%20texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mac\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# for nvidia GPUs\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = renameColumnsTrain(df)\n",
    "df_cleaned = df_cleaned[:5000] # change accordingly to the size of dataset you want to train on\n",
    "df_cleaned = filterNan(df_cleaned)\n",
    "df_cleaned['gold_label'] = encode_labels(df_cleaned['gold_label'])\n",
    "# split the data into training and validation sets before processing\n",
    "train_size = int(0.8 * len(df_cleaned))\n",
    "val_size = len(df_cleaned) - train_size\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(df_cleaned, [train_size, val_size])\n",
    "train_dataset = train_dataset.dataset\n",
    "val_dataset = val_dataset.dataset\n",
    "\n",
    "tokenized_input_train = tokenize(train_dataset)\n",
    "tokenized_input_val = tokenize(val_dataset)\n",
    "train_labels = convert_to_tensors(train_dataset['gold_label'])\n",
    "val_labels = convert_to_tensors(val_dataset['gold_label'])\n",
    "\n",
    "\n",
    "# actual_labels = convert_to_tensors(df_cleaned['gold_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0, 18377,    14,    10,   621,    15,    10,  5253, 13855,    81,\n",
       "            10,  3187,   159, 16847,     6,    24,    16, 45936,    14,    10,\n",
       "           621,    16,  1058,    39,  5253,    13,    10,  1465,     6,   142,\n",
       "             5,   621,    16,    45,  4784,  1058,    39,  5253,     4,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template goes like this:\n",
    "\n",
    "Given that [PREMISE] it is hypothesized that [HYPOTHESIS]. This is <mask> because [EXPLANATION]\n",
    "\n",
    "if model predicts contradict then,\n",
    "\n",
    "Given that a person on a horse jumps over a broken down airplane, it is hypothesized that a person is training his horse for a competition. This is <span style=\"color:red\">contradiction</span> because the person is not necessarily training his horse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token = tokenizer.mask_token\n",
    "template = \"Given that {}, it is hypothesized that {}. This is {} because {}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_premise = df_cleaned['premise'][0].lower()\n",
    "sample_premise = sample_premise[:-1] if sample_premise[-1] in ['.', '!', '?'] else sample_premise\n",
    "sample_hypothesis = df_cleaned['hypothesis'][0].lower()\n",
    "sample_hypothesis = sample_hypothesis[:-1] if sample_hypothesis[-1] in ['.', '!', '?'] else sample_hypothesis\n",
    "sample_explanation = df_cleaned['explanation'][0].lower()\n",
    "sample_explanation = sample_explanation[:-1] if sample_explanation[-1] in ['.', '!', '?'] else sample_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(template.format(sample_premise, sample_hypothesis, mask_token, sample_explanation),\n",
    "                          padding=\"max_length\",\n",
    "                          truncation=True,\n",
    "                          return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>Given that a person on a horse jumps over a broken down airplane, it is hypothesized that a person is training his horse for a competition. This is<mask> because the person is not necessarily training his horse.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(encoded_input.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input.attention_mask # 1's are for the actual input tokens, 0's are for the padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RoBERTa doesn't have token_type_ids, separate with </s> or tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask = encoded_input.values()\n",
    "output = model(input_ids=input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), 'neutral', 'neutral')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = output.logits.argmax()\n",
    "pred, id_to_label[pred.item()], id_to_label[df_cleaned['gold_label'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict without training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_template = 'Given that {}, it is hypothesized that {}.'\n",
    "explanation_template = ' because {}.'\n",
    "\n",
    "class eSNLIDataset(Dataset):\n",
    "    def __init__(self, df, train=True):\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx,:]\n",
    "        premise = example[\"premise\"]\n",
    "        hypothesis = example[\"hypothesis\"]\n",
    "        explanation = example[\"explanation\"]\n",
    "\n",
    "        premise = premise_template.format(premise, hypothesis)\n",
    "        explanation = explanation_template.format(explanation)\n",
    "\n",
    "        if self.train:\n",
    "            label = example[\"gold_label\"]\n",
    "            return premise, explanation, label\n",
    "        \n",
    "        return premise, explanation\n",
    "\n",
    "labels = train_labels\n",
    "\n",
    "dataset = eSNLIDataset(train_dataset, train=False) # just for testing\n",
    "dataloader = DataLoader(dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        premise, explanation = batch\n",
    "        encoded_input = tokenizer(premise, explanation, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        predictions.extend(logits.argmax(dim=-1).cpu().tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49804746170021025, 0.3316, 0.16601582056673678)\n"
     ]
    }
   ],
   "source": [
    "print(calc_f1_score(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# print(tokenized_input)\n",
    "input_ids = [x['input_ids'].squeeze(0) for x in tokenized_input_train]\n",
    "input_ids = pad_sequence(input_ids, batch_first=True)\n",
    "attention_masks = [x['attention_mask'].squeeze(0) for x in tokenized_input_train]\n",
    "attention_masks = pad_sequence(attention_masks, batch_first=True)\n",
    "\n",
    "labels = train_labels\n",
    "\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "loader = DataLoader(dataset, batch_size=16)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        batch_input_ids, batch_attention_mask, batch_labels = batch\n",
    "\n",
    "        batch_input_ids = batch_input_ids.to(device)\n",
    "        batch_attention_mask = batch_attention_mask.to(device)\n",
    "        \n",
    "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "predictions = torch.stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def calc_f1_score(predicted_classes, actual_labels):\n",
    "    return f1_score(predicted_classes, actual_labels, average='weighted'), f1_score(predicted_classes, actual_labels, average='micro'), f1_score(predicted_classes, actual_labels, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49804746170021025, 0.3316, 0.16601582056673678)\n"
     ]
    }
   ],
   "source": [
    "print(calc_f1_score(predictions, labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop using Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dombrr/anaconda3/lib/python3.11/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f7bed7fecc345639ad4737aa4b66acb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7144, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.716, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 0.7095, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.7117, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 0.7076, 'learning_rate': 5e-06, 'epoch': 0.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b21b351eec4710bc0ddb4644ea2ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7053645253181458, 'eval_runtime': 196.2196, 'eval_samples_per_second': 25.482, 'eval_steps_per_second': 0.403, 'epoch': 0.16}\n",
      "{'loss': 0.7033, 'learning_rate': 6e-06, 'epoch': 0.19}\n",
      "{'loss': 0.705, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 0.696, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 0.6886, 'learning_rate': 9e-06, 'epoch': 0.29}\n",
      "{'loss': 0.6944, 'learning_rate': 1e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de6c90325154a178c534f6940f0f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6850722432136536, 'eval_runtime': 202.136, 'eval_samples_per_second': 24.736, 'eval_steps_per_second': 0.391, 'epoch': 0.32}\n",
      "{'loss': 0.6781, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.35}\n",
      "{'loss': 0.6848, 'learning_rate': 1.2e-05, 'epoch': 0.38}\n",
      "{'loss': 0.6723, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.42}\n",
      "{'loss': 0.6642, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.45}\n",
      "{'loss': 0.663, 'learning_rate': 1.5e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841a6805132742c7a0ff2272d5563c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6625556349754333, 'eval_runtime': 198.0308, 'eval_samples_per_second': 25.249, 'eval_steps_per_second': 0.399, 'epoch': 0.48}\n",
      "{'loss': 0.6562, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.51}\n",
      "{'loss': 0.6558, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 0.6527, 'learning_rate': 1.8e-05, 'epoch': 0.58}\n",
      "{'loss': 0.6491, 'learning_rate': 1.9e-05, 'epoch': 0.61}\n",
      "{'loss': 0.6523, 'learning_rate': 2e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555edace5e434766ad125e99f6b64432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6488460898399353, 'eval_runtime': 194.2217, 'eval_samples_per_second': 25.744, 'eval_steps_per_second': 0.407, 'epoch': 0.64}\n",
      "{'loss': 0.6511, 'learning_rate': 2.1e-05, 'epoch': 0.67}\n",
      "{'loss': 0.6468, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.7}\n",
      "{'loss': 0.6461, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.73}\n",
      "{'loss': 0.6488, 'learning_rate': 2.4e-05, 'epoch': 0.77}\n",
      "{'loss': 0.6462, 'learning_rate': 2.5e-05, 'epoch': 0.8}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1faf934fef824772a58e142c0c5beffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6406314969062805, 'eval_runtime': 192.0931, 'eval_samples_per_second': 26.029, 'eval_steps_per_second': 0.411, 'epoch': 0.8}\n",
      "{'loss': 0.6427, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.83}\n",
      "{'loss': 0.6398, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.86}\n",
      "{'loss': 0.6417, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.89}\n",
      "{'loss': 0.6425, 'learning_rate': 2.9e-05, 'epoch': 0.93}\n",
      "{'loss': 0.6439, 'learning_rate': 3e-05, 'epoch': 0.96}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f66d41d61c4d7ba7928295c36160c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.637536883354187, 'eval_runtime': 197.4539, 'eval_samples_per_second': 25.322, 'eval_steps_per_second': 0.4, 'epoch': 0.96}\n",
      "{'loss': 0.6416, 'learning_rate': 3.1e-05, 'epoch': 0.99}\n",
      "{'loss': 0.6424, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.02}\n",
      "{'loss': 0.6402, 'learning_rate': 3.3e-05, 'epoch': 1.05}\n",
      "{'loss': 0.6416, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.09}\n",
      "{'loss': 0.6405, 'learning_rate': 3.5e-05, 'epoch': 1.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19eb2dd590542d684ab78031fbab5c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6355772614479065, 'eval_runtime': 197.744, 'eval_samples_per_second': 25.285, 'eval_steps_per_second': 0.4, 'epoch': 1.12}\n",
      "{'loss': 0.6378, 'learning_rate': 3.6e-05, 'epoch': 1.15}\n",
      "{'loss': 0.6363, 'learning_rate': 3.7e-05, 'epoch': 1.18}\n",
      "{'loss': 0.6377, 'learning_rate': 3.8e-05, 'epoch': 1.21}\n",
      "{'loss': 0.6426, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.25}\n",
      "{'loss': 0.641, 'learning_rate': 4e-05, 'epoch': 1.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2daa699b58e4283ae6cbc593a8c08dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6345017552375793, 'eval_runtime': 197.1772, 'eval_samples_per_second': 25.358, 'eval_steps_per_second': 0.401, 'epoch': 1.28}\n",
      "{'loss': 0.637, 'learning_rate': 4.1e-05, 'epoch': 1.31}\n",
      "{'loss': 0.6383, 'learning_rate': 4.2e-05, 'epoch': 1.34}\n",
      "{'loss': 0.6384, 'learning_rate': 4.3e-05, 'epoch': 1.37}\n",
      "{'loss': 0.6354, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.41}\n",
      "{'loss': 0.6414, 'learning_rate': 4.5e-05, 'epoch': 1.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8314b01ab922467ba6f081b11079a0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6342917680740356, 'eval_runtime': 193.368, 'eval_samples_per_second': 25.857, 'eval_steps_per_second': 0.409, 'epoch': 1.44}\n",
      "{'loss': 0.6417, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.47}\n",
      "{'loss': 0.6354, 'learning_rate': 4.7e-05, 'epoch': 1.5}\n",
      "{'loss': 0.635, 'learning_rate': 4.8e-05, 'epoch': 1.53}\n",
      "{'loss': 0.6392, 'learning_rate': 4.9e-05, 'epoch': 1.57}\n",
      "{'loss': 0.6356, 'learning_rate': 5e-05, 'epoch': 1.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2332c91487624260a73c1abebe11357a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.633437991142273, 'eval_runtime': 214.072, 'eval_samples_per_second': 23.357, 'eval_steps_per_second': 0.369, 'epoch': 1.6}\n",
      "{'loss': 0.6397, 'learning_rate': 4.980988593155894e-05, 'epoch': 1.63}\n",
      "{'loss': 0.6387, 'learning_rate': 4.9619771863117875e-05, 'epoch': 1.66}\n",
      "{'loss': 0.6383, 'learning_rate': 4.942965779467681e-05, 'epoch': 1.69}\n",
      "{'loss': 0.6365, 'learning_rate': 4.923954372623574e-05, 'epoch': 1.73}\n",
      "{'loss': 0.6326, 'learning_rate': 4.904942965779468e-05, 'epoch': 1.76}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed6866b872b4ab0896bdf050b228205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6319358348846436, 'eval_runtime': 209.352, 'eval_samples_per_second': 23.883, 'eval_steps_per_second': 0.377, 'epoch': 1.76}\n",
      "{'loss': 0.6374, 'learning_rate': 4.8859315589353615e-05, 'epoch': 1.79}\n",
      "{'loss': 0.6349, 'learning_rate': 4.866920152091255e-05, 'epoch': 1.82}\n",
      "{'loss': 0.6342, 'learning_rate': 4.847908745247148e-05, 'epoch': 1.85}\n",
      "{'loss': 0.6384, 'learning_rate': 4.8288973384030424e-05, 'epoch': 1.88}\n",
      "{'loss': 0.6341, 'learning_rate': 4.8098859315589354e-05, 'epoch': 1.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a85c497552e4b70add655c9c25062cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6312624216079712, 'eval_runtime': 205.5102, 'eval_samples_per_second': 24.33, 'eval_steps_per_second': 0.384, 'epoch': 1.92}\n",
      "{'loss': 0.6295, 'learning_rate': 4.790874524714829e-05, 'epoch': 1.95}\n",
      "{'loss': 0.6405, 'learning_rate': 4.771863117870723e-05, 'epoch': 1.98}\n",
      "{'loss': 0.635, 'learning_rate': 4.7528517110266163e-05, 'epoch': 2.01}\n",
      "{'loss': 0.6362, 'learning_rate': 4.73384030418251e-05, 'epoch': 2.04}\n",
      "{'loss': 0.6288, 'learning_rate': 4.714828897338403e-05, 'epoch': 2.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2777f29b94b4aec95a84030b448de9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6302877068519592, 'eval_runtime': 196.4629, 'eval_samples_per_second': 25.45, 'eval_steps_per_second': 0.402, 'epoch': 2.08}\n",
      "{'loss': 0.6336, 'learning_rate': 4.695817490494297e-05, 'epoch': 2.11}\n",
      "{'loss': 0.6347, 'learning_rate': 4.67680608365019e-05, 'epoch': 2.14}\n",
      "{'loss': 0.6344, 'learning_rate': 4.657794676806084e-05, 'epoch': 2.17}\n",
      "{'loss': 0.6274, 'learning_rate': 4.6387832699619776e-05, 'epoch': 2.2}\n",
      "{'loss': 0.63, 'learning_rate': 4.619771863117871e-05, 'epoch': 2.24}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5dbc0e13d847a3bb1cc47b70ff3260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6298921704292297, 'eval_runtime': 197.3809, 'eval_samples_per_second': 25.332, 'eval_steps_per_second': 0.4, 'epoch': 2.24}\n",
      "{'loss': 0.6298, 'learning_rate': 4.600760456273764e-05, 'epoch': 2.27}\n",
      "{'loss': 0.6372, 'learning_rate': 4.581749049429658e-05, 'epoch': 2.3}\n",
      "{'loss': 0.6287, 'learning_rate': 4.5627376425855515e-05, 'epoch': 2.33}\n",
      "{'loss': 0.6313, 'learning_rate': 4.543726235741445e-05, 'epoch': 2.36}\n",
      "{'loss': 0.627, 'learning_rate': 4.524714828897338e-05, 'epoch': 2.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6002b52d59e247eba177f8db6ccfb034",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.628957211971283, 'eval_runtime': 205.3187, 'eval_samples_per_second': 24.352, 'eval_steps_per_second': 0.385, 'epoch': 2.4}\n",
      "{'loss': 0.6303, 'learning_rate': 4.5057034220532325e-05, 'epoch': 2.43}\n",
      "{'loss': 0.6282, 'learning_rate': 4.4866920152091254e-05, 'epoch': 2.46}\n",
      "{'loss': 0.6327, 'learning_rate': 4.467680608365019e-05, 'epoch': 2.49}\n",
      "{'loss': 0.6304, 'learning_rate': 4.448669201520913e-05, 'epoch': 2.52}\n",
      "{'loss': 0.6319, 'learning_rate': 4.4296577946768064e-05, 'epoch': 2.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10df493b1b74fc2a93b6c7d218c15a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6277164816856384, 'eval_runtime': 204.3202, 'eval_samples_per_second': 24.471, 'eval_steps_per_second': 0.387, 'epoch': 2.56}\n",
      "{'loss': 0.6286, 'learning_rate': 4.4106463878327e-05, 'epoch': 2.59}\n",
      "{'loss': 0.6282, 'learning_rate': 4.391634980988593e-05, 'epoch': 2.62}\n",
      "{'loss': 0.6317, 'learning_rate': 4.3726235741444873e-05, 'epoch': 2.65}\n",
      "{'loss': 0.6309, 'learning_rate': 4.35361216730038e-05, 'epoch': 2.68}\n",
      "{'loss': 0.6303, 'learning_rate': 4.334600760456274e-05, 'epoch': 2.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632805e25ec8483a8a971dde9cd75d87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6268128156661987, 'eval_runtime': 199.3827, 'eval_samples_per_second': 25.077, 'eval_steps_per_second': 0.396, 'epoch': 2.72}\n",
      "{'loss': 0.6308, 'learning_rate': 4.3155893536121676e-05, 'epoch': 2.75}\n",
      "{'loss': 0.6254, 'learning_rate': 4.296577946768061e-05, 'epoch': 2.78}\n",
      "{'loss': 0.6297, 'learning_rate': 4.277566539923954e-05, 'epoch': 2.81}\n",
      "{'loss': 0.6295, 'learning_rate': 4.258555133079848e-05, 'epoch': 2.84}\n",
      "{'loss': 0.6262, 'learning_rate': 4.2395437262357415e-05, 'epoch': 2.88}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b991e90dbf4903b00fa11d9708a9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6266138553619385, 'eval_runtime': 204.2653, 'eval_samples_per_second': 24.478, 'eval_steps_per_second': 0.387, 'epoch': 2.88}\n",
      "{'loss': 0.6278, 'learning_rate': 4.220532319391635e-05, 'epoch': 2.91}\n",
      "{'loss': 0.6259, 'learning_rate': 4.201520912547529e-05, 'epoch': 2.94}\n",
      "{'loss': 0.626, 'learning_rate': 4.1825095057034225e-05, 'epoch': 2.97}\n",
      "{'loss': 0.6271, 'learning_rate': 4.163498098859316e-05, 'epoch': 3.0}\n",
      "{'loss': 0.6251, 'learning_rate': 4.144486692015209e-05, 'epoch': 3.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f94c0924d4403b94ba3d7659de862a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6256536841392517, 'eval_runtime': 204.9242, 'eval_samples_per_second': 24.399, 'eval_steps_per_second': 0.386, 'epoch': 3.04}\n",
      "{'loss': 0.6256, 'learning_rate': 4.125475285171103e-05, 'epoch': 3.07}\n",
      "{'loss': 0.6251, 'learning_rate': 4.1064638783269964e-05, 'epoch': 3.1}\n",
      "{'loss': 0.6278, 'learning_rate': 4.08745247148289e-05, 'epoch': 3.13}\n",
      "{'loss': 0.6297, 'learning_rate': 4.068441064638783e-05, 'epoch': 3.16}\n",
      "{'loss': 0.6211, 'learning_rate': 4.0494296577946774e-05, 'epoch': 3.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2a590afb8f40039d9825c5b4a34410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6245977878570557, 'eval_runtime': 205.189, 'eval_samples_per_second': 24.368, 'eval_steps_per_second': 0.385, 'epoch': 3.19}\n",
      "{'loss': 0.6227, 'learning_rate': 4.0304182509505703e-05, 'epoch': 3.23}\n",
      "{'loss': 0.6292, 'learning_rate': 4.011406844106464e-05, 'epoch': 3.26}\n",
      "{'loss': 0.6262, 'learning_rate': 3.9923954372623577e-05, 'epoch': 3.29}\n",
      "{'loss': 0.6221, 'learning_rate': 3.973384030418251e-05, 'epoch': 3.32}\n",
      "{'loss': 0.6249, 'learning_rate': 3.954372623574145e-05, 'epoch': 3.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce7c79475bd4d2cb49c4bc0585e879d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6237746477127075, 'eval_runtime': 202.3721, 'eval_samples_per_second': 24.707, 'eval_steps_per_second': 0.39, 'epoch': 3.35}\n",
      "{'loss': 0.6253, 'learning_rate': 3.935361216730038e-05, 'epoch': 3.39}\n",
      "{'loss': 0.6242, 'learning_rate': 3.916349809885932e-05, 'epoch': 3.42}\n",
      "{'loss': 0.6234, 'learning_rate': 3.897338403041825e-05, 'epoch': 3.45}\n",
      "{'loss': 0.6214, 'learning_rate': 3.878326996197719e-05, 'epoch': 3.48}\n",
      "{'loss': 0.6247, 'learning_rate': 3.8593155893536125e-05, 'epoch': 3.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93473d942ce04dbe9e9e2f259c61d0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6228663921356201, 'eval_runtime': 204.8808, 'eval_samples_per_second': 24.404, 'eval_steps_per_second': 0.386, 'epoch': 3.51}\n",
      "{'loss': 0.6273, 'learning_rate': 3.840304182509506e-05, 'epoch': 3.55}\n",
      "{'loss': 0.6303, 'learning_rate': 3.821292775665399e-05, 'epoch': 3.58}\n",
      "{'loss': 0.624, 'learning_rate': 3.802281368821293e-05, 'epoch': 3.61}\n",
      "{'loss': 0.6194, 'learning_rate': 3.7832699619771865e-05, 'epoch': 3.64}\n",
      "{'loss': 0.6197, 'learning_rate': 3.76425855513308e-05, 'epoch': 3.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdc943f3fc33487eb20f7cee2d698bc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6223964095115662, 'eval_runtime': 204.8504, 'eval_samples_per_second': 24.408, 'eval_steps_per_second': 0.386, 'epoch': 3.67}\n",
      "{'loss': 0.626, 'learning_rate': 3.745247148288973e-05, 'epoch': 3.71}\n",
      "{'loss': 0.6189, 'learning_rate': 3.7262357414448674e-05, 'epoch': 3.74}\n",
      "{'loss': 0.6278, 'learning_rate': 3.7072243346007604e-05, 'epoch': 3.77}\n",
      "{'loss': 0.6225, 'learning_rate': 3.688212927756654e-05, 'epoch': 3.8}\n",
      "{'loss': 0.6232, 'learning_rate': 3.669201520912548e-05, 'epoch': 3.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b641fa6a0eb4dd69d51bac9f076b6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.621483564376831, 'eval_runtime': 194.585, 'eval_samples_per_second': 25.696, 'eval_steps_per_second': 0.406, 'epoch': 3.83}\n",
      "{'loss': 0.6258, 'learning_rate': 3.6501901140684413e-05, 'epoch': 3.87}\n",
      "{'loss': 0.6254, 'learning_rate': 3.631178707224335e-05, 'epoch': 3.9}\n",
      "{'loss': 0.6265, 'learning_rate': 3.612167300380228e-05, 'epoch': 3.93}\n",
      "{'loss': 0.6225, 'learning_rate': 3.593155893536122e-05, 'epoch': 3.96}\n",
      "{'loss': 0.6212, 'learning_rate': 3.574144486692015e-05, 'epoch': 3.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "babdef59605d49ffa34265fb235473af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.620911717414856, 'eval_runtime': 202.3112, 'eval_samples_per_second': 24.714, 'eval_steps_per_second': 0.39, 'epoch': 3.99}\n",
      "{'loss': 0.6201, 'learning_rate': 3.555133079847909e-05, 'epoch': 4.03}\n",
      "{'loss': 0.6317, 'learning_rate': 3.5361216730038026e-05, 'epoch': 4.06}\n",
      "{'loss': 0.6178, 'learning_rate': 3.517110266159696e-05, 'epoch': 4.09}\n",
      "{'loss': 0.6173, 'learning_rate': 3.498098859315589e-05, 'epoch': 4.12}\n",
      "{'loss': 0.6229, 'learning_rate': 3.479087452471483e-05, 'epoch': 4.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c5073540e54e0aa161dfe35fd76ab1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6204317808151245, 'eval_runtime': 198.509, 'eval_samples_per_second': 25.188, 'eval_steps_per_second': 0.398, 'epoch': 4.15}\n",
      "{'loss': 0.621, 'learning_rate': 3.4600760456273765e-05, 'epoch': 4.19}\n",
      "{'loss': 0.6229, 'learning_rate': 3.44106463878327e-05, 'epoch': 4.22}\n",
      "{'loss': 0.6197, 'learning_rate': 3.422053231939164e-05, 'epoch': 4.25}\n",
      "{'loss': 0.6212, 'learning_rate': 3.4030418250950574e-05, 'epoch': 4.28}\n",
      "{'loss': 0.6191, 'learning_rate': 3.384030418250951e-05, 'epoch': 4.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4db034b2a7d4f02b8e0c9ce17319af4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.619526743888855, 'eval_runtime': 197.178, 'eval_samples_per_second': 25.358, 'eval_steps_per_second': 0.401, 'epoch': 4.31}\n",
      "{'loss': 0.6202, 'learning_rate': 3.365019011406844e-05, 'epoch': 4.35}\n",
      "{'loss': 0.6198, 'learning_rate': 3.346007604562738e-05, 'epoch': 4.38}\n",
      "{'loss': 0.6292, 'learning_rate': 3.3269961977186314e-05, 'epoch': 4.41}\n",
      "{'loss': 0.6173, 'learning_rate': 3.307984790874525e-05, 'epoch': 4.44}\n",
      "{'loss': 0.6145, 'learning_rate': 3.288973384030418e-05, 'epoch': 4.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64153d741444f5b840ee6f7ee165043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6185753345489502, 'eval_runtime': 189.707, 'eval_samples_per_second': 26.356, 'eval_steps_per_second': 0.416, 'epoch': 4.47}\n",
      "{'loss': 0.6198, 'learning_rate': 3.269961977186312e-05, 'epoch': 4.5}\n",
      "{'loss': 0.616, 'learning_rate': 3.250950570342205e-05, 'epoch': 4.54}\n",
      "{'loss': 0.6161, 'learning_rate': 3.231939163498099e-05, 'epoch': 4.57}\n",
      "{'loss': 0.6159, 'learning_rate': 3.2129277566539926e-05, 'epoch': 4.6}\n",
      "{'loss': 0.6175, 'learning_rate': 3.193916349809886e-05, 'epoch': 4.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8171ae4c22304d968de3251757661672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6179611682891846, 'eval_runtime': 193.3709, 'eval_samples_per_second': 25.857, 'eval_steps_per_second': 0.409, 'epoch': 4.63}\n",
      "{'loss': 0.6197, 'learning_rate': 3.174904942965779e-05, 'epoch': 4.66}\n",
      "{'loss': 0.6212, 'learning_rate': 3.155893536121673e-05, 'epoch': 4.7}\n",
      "{'loss': 0.6129, 'learning_rate': 3.1368821292775665e-05, 'epoch': 4.73}\n",
      "{'loss': 0.6246, 'learning_rate': 3.11787072243346e-05, 'epoch': 4.76}\n",
      "{'loss': 0.6182, 'learning_rate': 3.098859315589354e-05, 'epoch': 4.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970956d3face408c9c2a7bbdd47e16f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6171596646308899, 'eval_runtime': 190.3297, 'eval_samples_per_second': 26.27, 'eval_steps_per_second': 0.415, 'epoch': 4.79}\n",
      "{'loss': 0.6218, 'learning_rate': 3.0798479087452475e-05, 'epoch': 4.82}\n",
      "{'loss': 0.6175, 'learning_rate': 3.060836501901141e-05, 'epoch': 4.86}\n",
      "{'loss': 0.6171, 'learning_rate': 3.041825095057034e-05, 'epoch': 4.89}\n",
      "{'loss': 0.6165, 'learning_rate': 3.0228136882129278e-05, 'epoch': 4.92}\n",
      "{'loss': 0.6176, 'learning_rate': 3.0038022813688214e-05, 'epoch': 4.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474e373dc93d43a8a5de933075717dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6168698072433472, 'eval_runtime': 204.4656, 'eval_samples_per_second': 24.454, 'eval_steps_per_second': 0.386, 'epoch': 4.95}\n",
      "{'loss': 0.6174, 'learning_rate': 2.984790874524715e-05, 'epoch': 4.98}\n",
      "{'loss': 0.6175, 'learning_rate': 2.9657794676806084e-05, 'epoch': 5.02}\n",
      "{'loss': 0.6149, 'learning_rate': 2.9467680608365024e-05, 'epoch': 5.05}\n",
      "{'loss': 0.6175, 'learning_rate': 2.9277566539923957e-05, 'epoch': 5.08}\n",
      "{'loss': 0.6237, 'learning_rate': 2.908745247148289e-05, 'epoch': 5.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3731c21eb30245308c5e0cd99f6014ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6160021424293518, 'eval_runtime': 201.1153, 'eval_samples_per_second': 24.861, 'eval_steps_per_second': 0.393, 'epoch': 5.11}\n",
      "{'loss': 0.6172, 'learning_rate': 2.8897338403041823e-05, 'epoch': 5.14}\n",
      "{'loss': 0.6126, 'learning_rate': 2.8707224334600763e-05, 'epoch': 5.18}\n",
      "{'loss': 0.6183, 'learning_rate': 2.8517110266159696e-05, 'epoch': 5.21}\n",
      "{'loss': 0.6116, 'learning_rate': 2.832699619771863e-05, 'epoch': 5.24}\n",
      "{'loss': 0.6216, 'learning_rate': 2.813688212927757e-05, 'epoch': 5.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7e9926a0804b7c82566142e92faea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6154322028160095, 'eval_runtime': 203.9195, 'eval_samples_per_second': 24.519, 'eval_steps_per_second': 0.387, 'epoch': 5.27}\n",
      "{'loss': 0.6176, 'learning_rate': 2.7946768060836502e-05, 'epoch': 5.3}\n",
      "{'loss': 0.6194, 'learning_rate': 2.775665399239544e-05, 'epoch': 5.34}\n",
      "{'loss': 0.6165, 'learning_rate': 2.7566539923954375e-05, 'epoch': 5.37}\n",
      "{'loss': 0.6162, 'learning_rate': 2.7376425855513312e-05, 'epoch': 5.4}\n",
      "{'loss': 0.6125, 'learning_rate': 2.7186311787072245e-05, 'epoch': 5.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "759690477af94a0e9ee6e38606af7a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6144956350326538, 'eval_runtime': 199.6586, 'eval_samples_per_second': 25.043, 'eval_steps_per_second': 0.396, 'epoch': 5.43}\n",
      "{'loss': 0.6149, 'learning_rate': 2.6996197718631178e-05, 'epoch': 5.46}\n",
      "{'loss': 0.6139, 'learning_rate': 2.6806083650190118e-05, 'epoch': 5.5}\n",
      "{'loss': 0.6143, 'learning_rate': 2.661596958174905e-05, 'epoch': 5.53}\n",
      "{'loss': 0.6113, 'learning_rate': 2.6425855513307984e-05, 'epoch': 5.56}\n",
      "{'loss': 0.6176, 'learning_rate': 2.6235741444866924e-05, 'epoch': 5.59}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d8b9e04d7a44fba849c399bf5b36c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.613808274269104, 'eval_runtime': 211.7733, 'eval_samples_per_second': 23.61, 'eval_steps_per_second': 0.373, 'epoch': 5.59}\n",
      "{'loss': 0.6171, 'learning_rate': 2.6045627376425857e-05, 'epoch': 5.62}\n",
      "{'loss': 0.6178, 'learning_rate': 2.585551330798479e-05, 'epoch': 5.65}\n",
      "{'loss': 0.6135, 'learning_rate': 2.5665399239543723e-05, 'epoch': 5.69}\n",
      "{'loss': 0.6153, 'learning_rate': 2.5475285171102663e-05, 'epoch': 5.72}\n",
      "{'loss': 0.6155, 'learning_rate': 2.5285171102661596e-05, 'epoch': 5.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d12b8681bbd64dd3ba10952243ad47c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.613182008266449, 'eval_runtime': 207.3071, 'eval_samples_per_second': 24.119, 'eval_steps_per_second': 0.381, 'epoch': 5.75}\n",
      "{'loss': 0.6175, 'learning_rate': 2.5095057034220533e-05, 'epoch': 5.78}\n",
      "{'loss': 0.6134, 'learning_rate': 2.490494296577947e-05, 'epoch': 5.81}\n",
      "{'loss': 0.6134, 'learning_rate': 2.4714828897338406e-05, 'epoch': 5.85}\n",
      "{'loss': 0.6184, 'learning_rate': 2.452471482889734e-05, 'epoch': 5.88}\n",
      "{'loss': 0.6087, 'learning_rate': 2.4334600760456276e-05, 'epoch': 5.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1998294a50394aaaba77c79b35e2008d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6128717064857483, 'eval_runtime': 201.09, 'eval_samples_per_second': 24.864, 'eval_steps_per_second': 0.393, 'epoch': 5.91}\n",
      "{'loss': 0.6124, 'learning_rate': 2.4144486692015212e-05, 'epoch': 5.94}\n",
      "{'loss': 0.6112, 'learning_rate': 2.3954372623574145e-05, 'epoch': 5.97}\n",
      "{'loss': 0.6085, 'learning_rate': 2.3764258555133082e-05, 'epoch': 6.01}\n",
      "{'loss': 0.6125, 'learning_rate': 2.3574144486692015e-05, 'epoch': 6.04}\n",
      "{'loss': 0.6186, 'learning_rate': 2.338403041825095e-05, 'epoch': 6.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6243ad4c6944c24b111589794b2c990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.612210750579834, 'eval_runtime': 194.0257, 'eval_samples_per_second': 25.77, 'eval_steps_per_second': 0.407, 'epoch': 6.07}\n",
      "{'loss': 0.6139, 'learning_rate': 2.3193916349809888e-05, 'epoch': 6.1}\n",
      "{'loss': 0.6128, 'learning_rate': 2.300380228136882e-05, 'epoch': 6.13}\n",
      "{'loss': 0.6203, 'learning_rate': 2.2813688212927758e-05, 'epoch': 6.17}\n",
      "{'loss': 0.6057, 'learning_rate': 2.262357414448669e-05, 'epoch': 6.2}\n",
      "{'loss': 0.6144, 'learning_rate': 2.2433460076045627e-05, 'epoch': 6.23}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d561f7f276b445b8d56b89c7eea7872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6115713119506836, 'eval_runtime': 196.2003, 'eval_samples_per_second': 25.484, 'eval_steps_per_second': 0.403, 'epoch': 6.23}\n",
      "{'loss': 0.6173, 'learning_rate': 2.2243346007604564e-05, 'epoch': 6.26}\n",
      "{'loss': 0.6071, 'learning_rate': 2.20532319391635e-05, 'epoch': 6.29}\n",
      "{'loss': 0.6148, 'learning_rate': 2.1863117870722437e-05, 'epoch': 6.33}\n",
      "{'loss': 0.6022, 'learning_rate': 2.167300380228137e-05, 'epoch': 6.36}\n",
      "{'loss': 0.6154, 'learning_rate': 2.1482889733840306e-05, 'epoch': 6.39}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73401746d4f34069890c8cb25b2c3313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6108203530311584, 'eval_runtime': 191.4336, 'eval_samples_per_second': 26.119, 'eval_steps_per_second': 0.413, 'epoch': 6.39}\n",
      "{'loss': 0.6209, 'learning_rate': 2.129277566539924e-05, 'epoch': 6.42}\n",
      "{'loss': 0.609, 'learning_rate': 2.1102661596958176e-05, 'epoch': 6.45}\n",
      "{'loss': 0.6125, 'learning_rate': 2.0912547528517112e-05, 'epoch': 6.49}\n",
      "{'loss': 0.6066, 'learning_rate': 2.0722433460076046e-05, 'epoch': 6.52}\n",
      "{'loss': 0.6063, 'learning_rate': 2.0532319391634982e-05, 'epoch': 6.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6719ec2143f24f57bbd5f758a1d7748e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6103072762489319, 'eval_runtime': 210.3317, 'eval_samples_per_second': 23.772, 'eval_steps_per_second': 0.376, 'epoch': 6.55}\n",
      "{'loss': 0.6055, 'learning_rate': 2.0342205323193915e-05, 'epoch': 6.58}\n",
      "{'loss': 0.6104, 'learning_rate': 2.0152091254752852e-05, 'epoch': 6.61}\n",
      "{'loss': 0.6193, 'learning_rate': 1.9961977186311788e-05, 'epoch': 6.65}\n",
      "{'loss': 0.6113, 'learning_rate': 1.9771863117870725e-05, 'epoch': 6.68}\n",
      "{'loss': 0.6036, 'learning_rate': 1.958174904942966e-05, 'epoch': 6.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827e7cdf3c8244809a19a75a174b773e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6098010540008545, 'eval_runtime': 205.1426, 'eval_samples_per_second': 24.373, 'eval_steps_per_second': 0.385, 'epoch': 6.71}\n",
      "{'loss': 0.6088, 'learning_rate': 1.9391634980988594e-05, 'epoch': 6.74}\n",
      "{'loss': 0.6156, 'learning_rate': 1.920152091254753e-05, 'epoch': 6.77}\n",
      "{'loss': 0.6191, 'learning_rate': 1.9011406844106464e-05, 'epoch': 6.81}\n",
      "{'loss': 0.6121, 'learning_rate': 1.88212927756654e-05, 'epoch': 6.84}\n",
      "{'loss': 0.6088, 'learning_rate': 1.8631178707224337e-05, 'epoch': 6.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174a4404b09149738903b88c3b030c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6092498302459717, 'eval_runtime': 208.1274, 'eval_samples_per_second': 24.024, 'eval_steps_per_second': 0.38, 'epoch': 6.87}\n",
      "{'loss': 0.6068, 'learning_rate': 1.844106463878327e-05, 'epoch': 6.9}\n",
      "{'loss': 0.6115, 'learning_rate': 1.8250950570342207e-05, 'epoch': 6.93}\n",
      "{'loss': 0.6076, 'learning_rate': 1.806083650190114e-05, 'epoch': 6.96}\n",
      "{'loss': 0.614, 'learning_rate': 1.7870722433460076e-05, 'epoch': 7.0}\n",
      "{'loss': 0.6113, 'learning_rate': 1.7680608365019013e-05, 'epoch': 7.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8428e19f531f4fcfb564b2db6c1bc660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6087948083877563, 'eval_runtime': 217.1364, 'eval_samples_per_second': 23.027, 'eval_steps_per_second': 0.364, 'epoch': 7.03}\n",
      "{'loss': 0.608, 'learning_rate': 1.7490494296577946e-05, 'epoch': 7.06}\n",
      "{'loss': 0.6001, 'learning_rate': 1.7300380228136882e-05, 'epoch': 7.09}\n",
      "{'loss': 0.6077, 'learning_rate': 1.711026615969582e-05, 'epoch': 7.12}\n",
      "{'loss': 0.6036, 'learning_rate': 1.6920152091254756e-05, 'epoch': 7.16}\n",
      "{'loss': 0.6086, 'learning_rate': 1.673003802281369e-05, 'epoch': 7.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994f3709197d47a6b9f5a6b1b6bd4375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6083433628082275, 'eval_runtime': 207.6299, 'eval_samples_per_second': 24.081, 'eval_steps_per_second': 0.38, 'epoch': 7.19}\n",
      "{'loss': 0.6105, 'learning_rate': 1.6539923954372625e-05, 'epoch': 7.22}\n",
      "{'loss': 0.605, 'learning_rate': 1.634980988593156e-05, 'epoch': 7.25}\n",
      "{'loss': 0.61, 'learning_rate': 1.6159695817490495e-05, 'epoch': 7.28}\n",
      "{'loss': 0.6085, 'learning_rate': 1.596958174904943e-05, 'epoch': 7.32}\n",
      "{'loss': 0.605, 'learning_rate': 1.5779467680608364e-05, 'epoch': 7.35}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c36fdf4c244418a955c6955b820da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6078518629074097, 'eval_runtime': 218.3705, 'eval_samples_per_second': 22.897, 'eval_steps_per_second': 0.362, 'epoch': 7.35}\n",
      "{'loss': 0.6056, 'learning_rate': 1.55893536121673e-05, 'epoch': 7.38}\n",
      "{'loss': 0.6078, 'learning_rate': 1.5399239543726237e-05, 'epoch': 7.41}\n",
      "{'loss': 0.6085, 'learning_rate': 1.520912547528517e-05, 'epoch': 7.44}\n",
      "{'loss': 0.6052, 'learning_rate': 1.5019011406844107e-05, 'epoch': 7.48}\n",
      "{'loss': 0.611, 'learning_rate': 1.4828897338403042e-05, 'epoch': 7.51}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc27eeaab234d64aaeacbb813aeca3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6075143218040466, 'eval_runtime': 191.8319, 'eval_samples_per_second': 26.064, 'eval_steps_per_second': 0.412, 'epoch': 7.51}\n",
      "{'loss': 0.618, 'learning_rate': 1.4638783269961978e-05, 'epoch': 7.54}\n",
      "{'loss': 0.6024, 'learning_rate': 1.4448669201520912e-05, 'epoch': 7.57}\n",
      "{'loss': 0.6055, 'learning_rate': 1.4258555133079848e-05, 'epoch': 7.6}\n",
      "{'loss': 0.6083, 'learning_rate': 1.4068441064638785e-05, 'epoch': 7.64}\n",
      "{'loss': 0.5968, 'learning_rate': 1.387832699619772e-05, 'epoch': 7.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ddba5c7ec4448aa5c5d4febd34df96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.60704505443573, 'eval_runtime': 191.3073, 'eval_samples_per_second': 26.136, 'eval_steps_per_second': 0.413, 'epoch': 7.67}\n",
      "{'loss': 0.6094, 'learning_rate': 1.3688212927756656e-05, 'epoch': 7.7}\n",
      "{'loss': 0.6067, 'learning_rate': 1.3498098859315589e-05, 'epoch': 7.73}\n",
      "{'loss': 0.6088, 'learning_rate': 1.3307984790874526e-05, 'epoch': 7.76}\n",
      "{'loss': 0.6039, 'learning_rate': 1.3117870722433462e-05, 'epoch': 7.8}\n",
      "{'loss': 0.6153, 'learning_rate': 1.2927756653992395e-05, 'epoch': 7.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfbdb351dde14c9abc006d357da2f966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6067071557044983, 'eval_runtime': 191.2575, 'eval_samples_per_second': 26.143, 'eval_steps_per_second': 0.413, 'epoch': 7.83}\n",
      "{'loss': 0.6105, 'learning_rate': 1.2737642585551332e-05, 'epoch': 7.86}\n",
      "{'loss': 0.6061, 'learning_rate': 1.2547528517110266e-05, 'epoch': 7.89}\n",
      "{'loss': 0.6059, 'learning_rate': 1.2357414448669203e-05, 'epoch': 7.92}\n",
      "{'loss': 0.607, 'learning_rate': 1.2167300380228138e-05, 'epoch': 7.96}\n",
      "{'loss': 0.6031, 'learning_rate': 1.1977186311787073e-05, 'epoch': 7.99}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c54af6d0d8ec47c282b75aa19189c24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6063896417617798, 'eval_runtime': 187.5426, 'eval_samples_per_second': 26.661, 'eval_steps_per_second': 0.421, 'epoch': 7.99}\n",
      "{'loss': 0.6159, 'learning_rate': 1.1787072243346007e-05, 'epoch': 8.02}\n",
      "{'loss': 0.6078, 'learning_rate': 1.1596958174904944e-05, 'epoch': 8.05}\n",
      "{'loss': 0.6092, 'learning_rate': 1.1406844106463879e-05, 'epoch': 8.08}\n",
      "{'loss': 0.6022, 'learning_rate': 1.1216730038022814e-05, 'epoch': 8.12}\n",
      "{'loss': 0.6099, 'learning_rate': 1.102661596958175e-05, 'epoch': 8.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7272d91db09241f982de4d5e8729fa54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6061394810676575, 'eval_runtime': 190.3995, 'eval_samples_per_second': 26.261, 'eval_steps_per_second': 0.415, 'epoch': 8.15}\n",
      "{'loss': 0.603, 'learning_rate': 1.0836501901140685e-05, 'epoch': 8.18}\n",
      "{'loss': 0.6033, 'learning_rate': 1.064638783269962e-05, 'epoch': 8.21}\n",
      "{'loss': 0.6078, 'learning_rate': 1.0456273764258556e-05, 'epoch': 8.24}\n",
      "{'loss': 0.614, 'learning_rate': 1.0266159695817491e-05, 'epoch': 8.27}\n",
      "{'loss': 0.6157, 'learning_rate': 1.0076045627376426e-05, 'epoch': 8.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385afb579b504e259f9d68eac272519d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.605705976486206, 'eval_runtime': 189.6944, 'eval_samples_per_second': 26.358, 'eval_steps_per_second': 0.416, 'epoch': 8.31}\n",
      "{'loss': 0.6168, 'learning_rate': 9.885931558935362e-06, 'epoch': 8.34}\n",
      "{'loss': 0.6005, 'learning_rate': 9.695817490494297e-06, 'epoch': 8.37}\n",
      "{'loss': 0.601, 'learning_rate': 9.505703422053232e-06, 'epoch': 8.4}\n",
      "{'loss': 0.6074, 'learning_rate': 9.315589353612169e-06, 'epoch': 8.43}\n",
      "{'loss': 0.6052, 'learning_rate': 9.125475285171103e-06, 'epoch': 8.47}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41052ce399f24380b1bae545d2664f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6055253148078918, 'eval_runtime': 188.8155, 'eval_samples_per_second': 26.481, 'eval_steps_per_second': 0.418, 'epoch': 8.47}\n",
      "{'loss': 0.6153, 'learning_rate': 8.935361216730038e-06, 'epoch': 8.5}\n",
      "{'loss': 0.6068, 'learning_rate': 8.745247148288973e-06, 'epoch': 8.53}\n",
      "{'loss': 0.605, 'learning_rate': 8.55513307984791e-06, 'epoch': 8.56}\n",
      "{'loss': 0.6019, 'learning_rate': 8.365019011406844e-06, 'epoch': 8.59}\n",
      "{'loss': 0.5993, 'learning_rate': 8.17490494296578e-06, 'epoch': 8.63}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3f4023052244019b1392df8d48cfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6052126884460449, 'eval_runtime': 189.9948, 'eval_samples_per_second': 26.317, 'eval_steps_per_second': 0.416, 'epoch': 8.63}\n",
      "{'loss': 0.6016, 'learning_rate': 7.984790874524716e-06, 'epoch': 8.66}\n",
      "{'loss': 0.5989, 'learning_rate': 7.79467680608365e-06, 'epoch': 8.69}\n",
      "{'loss': 0.6026, 'learning_rate': 7.604562737642585e-06, 'epoch': 8.72}\n",
      "{'loss': 0.603, 'learning_rate': 7.414448669201521e-06, 'epoch': 8.75}\n",
      "{'loss': 0.601, 'learning_rate': 7.224334600760456e-06, 'epoch': 8.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e488f2d1b7b748ce83115db2d72d5244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6049203872680664, 'eval_runtime': 191.754, 'eval_samples_per_second': 26.075, 'eval_steps_per_second': 0.412, 'epoch': 8.79}\n",
      "{'loss': 0.6028, 'learning_rate': 7.034220532319392e-06, 'epoch': 8.82}\n",
      "{'loss': 0.6052, 'learning_rate': 6.844106463878328e-06, 'epoch': 8.85}\n",
      "{'loss': 0.6043, 'learning_rate': 6.653992395437263e-06, 'epoch': 8.88}\n",
      "{'loss': 0.5996, 'learning_rate': 6.4638783269961976e-06, 'epoch': 8.91}\n",
      "{'loss': 0.6081, 'learning_rate': 6.273764258555133e-06, 'epoch': 8.95}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3aa36441a14a1eb0d4280b447c9a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6047185659408569, 'eval_runtime': 193.3977, 'eval_samples_per_second': 25.853, 'eval_steps_per_second': 0.408, 'epoch': 8.95}\n",
      "{'loss': 0.6041, 'learning_rate': 6.083650190114069e-06, 'epoch': 8.98}\n",
      "{'loss': 0.6034, 'learning_rate': 5.893536121673004e-06, 'epoch': 9.01}\n",
      "{'loss': 0.604, 'learning_rate': 5.703422053231939e-06, 'epoch': 9.04}\n",
      "{'loss': 0.6036, 'learning_rate': 5.513307984790875e-06, 'epoch': 9.07}\n",
      "{'loss': 0.6067, 'learning_rate': 5.32319391634981e-06, 'epoch': 9.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d287015c12864f5489248eaf61147028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6045900583267212, 'eval_runtime': 193.8316, 'eval_samples_per_second': 25.796, 'eval_steps_per_second': 0.408, 'epoch': 9.11}\n",
      "{'loss': 0.6061, 'learning_rate': 5.1330798479087455e-06, 'epoch': 9.14}\n",
      "{'loss': 0.6008, 'learning_rate': 4.942965779467681e-06, 'epoch': 9.17}\n",
      "{'loss': 0.6051, 'learning_rate': 4.752851711026616e-06, 'epoch': 9.2}\n",
      "{'loss': 0.6051, 'learning_rate': 4.562737642585552e-06, 'epoch': 9.23}\n",
      "{'loss': 0.6046, 'learning_rate': 4.3726235741444865e-06, 'epoch': 9.27}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8101ec812044cbc86db5384c916a09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6044347286224365, 'eval_runtime': 192.085, 'eval_samples_per_second': 26.03, 'eval_steps_per_second': 0.411, 'epoch': 9.27}\n",
      "{'loss': 0.603, 'learning_rate': 4.182509505703422e-06, 'epoch': 9.3}\n",
      "{'loss': 0.6066, 'learning_rate': 3.992395437262358e-06, 'epoch': 9.33}\n",
      "{'loss': 0.6069, 'learning_rate': 3.8022813688212926e-06, 'epoch': 9.36}\n",
      "{'loss': 0.608, 'learning_rate': 3.612167300380228e-06, 'epoch': 9.39}\n",
      "{'loss': 0.5935, 'learning_rate': 3.422053231939164e-06, 'epoch': 9.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fb2313691944da844ae688a10253fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6042946577072144, 'eval_runtime': 191.4129, 'eval_samples_per_second': 26.122, 'eval_steps_per_second': 0.413, 'epoch': 9.42}\n",
      "{'loss': 0.6026, 'learning_rate': 3.2319391634980988e-06, 'epoch': 9.46}\n",
      "{'loss': 0.6082, 'learning_rate': 3.0418250950570345e-06, 'epoch': 9.49}\n",
      "{'loss': 0.602, 'learning_rate': 2.8517110266159697e-06, 'epoch': 9.52}\n",
      "{'loss': 0.6096, 'learning_rate': 2.661596958174905e-06, 'epoch': 9.55}\n",
      "{'loss': 0.6037, 'learning_rate': 2.4714828897338406e-06, 'epoch': 9.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02429c7fae81458aa8afc9567dadc6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6042035818099976, 'eval_runtime': 191.6875, 'eval_samples_per_second': 26.084, 'eval_steps_per_second': 0.412, 'epoch': 9.58}\n",
      "{'loss': 0.6043, 'learning_rate': 2.281368821292776e-06, 'epoch': 9.62}\n",
      "{'loss': 0.6014, 'learning_rate': 2.091254752851711e-06, 'epoch': 9.65}\n",
      "{'loss': 0.598, 'learning_rate': 1.9011406844106463e-06, 'epoch': 9.68}\n",
      "{'loss': 0.6029, 'learning_rate': 1.711026615969582e-06, 'epoch': 9.71}\n",
      "{'loss': 0.6037, 'learning_rate': 1.5209125475285172e-06, 'epoch': 9.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fbfc0d9c3343c688a7a5dd92dd785d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6041309833526611, 'eval_runtime': 193.5476, 'eval_samples_per_second': 25.833, 'eval_steps_per_second': 0.408, 'epoch': 9.74}\n",
      "{'loss': 0.6026, 'learning_rate': 1.3307984790874525e-06, 'epoch': 9.78}\n",
      "{'loss': 0.5979, 'learning_rate': 1.140684410646388e-06, 'epoch': 9.81}\n",
      "{'loss': 0.6043, 'learning_rate': 9.505703422053232e-07, 'epoch': 9.84}\n",
      "{'loss': 0.6009, 'learning_rate': 7.604562737642586e-07, 'epoch': 9.87}\n",
      "{'loss': 0.5985, 'learning_rate': 5.70342205323194e-07, 'epoch': 9.9}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4220915e0614a9da3efbc937d7bae77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/79 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6041001081466675, 'eval_runtime': 191.7254, 'eval_samples_per_second': 26.079, 'eval_steps_per_second': 0.412, 'epoch': 9.9}\n",
      "{'loss': 0.6022, 'learning_rate': 3.802281368821293e-07, 'epoch': 9.94}\n",
      "{'loss': 0.6121, 'learning_rate': 1.9011406844106465e-07, 'epoch': 9.97}\n",
      "{'loss': 0.6032, 'learning_rate': 0.0, 'epoch': 10.0}\n",
      "{'train_runtime': 16153.6749, 'train_samples_per_second': 3.095, 'train_steps_per_second': 0.194, 'train_loss': 0.6225034703081027, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3130, training_loss=0.6225034703081027, metrics={'train_runtime': 16153.6749, 'train_samples_per_second': 3.095, 'train_steps_per_second': 0.194, 'train_loss': 0.6225034703081027, 'epoch': 10.0})"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, TensorDataset\n",
    "import torch\n",
    "\n",
    "# freeze all the parameters in the base model\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only train the classification head\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# need to wrap in a dictionary to use the Trainer class\n",
    "class DictDataset(Dataset):\n",
    "    def __init__(self, tensor_dataset):\n",
    "        self.tensor_dataset = tensor_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tensor_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids, attention_mask, labels = self.tensor_dataset[idx]\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': labels\n",
    "        }\n",
    "\n",
    "input_ids_train = [x['input_ids'].squeeze(0) for x in tokenized_input_train]\n",
    "input_ids_train = torch.nn.utils.rnn.pad_sequence(input_ids_train, batch_first=True)\n",
    "attention_masks_train = [x['attention_mask'].squeeze(0) for x in tokenized_input_train]\n",
    "attention_masks_train = torch.nn.utils.rnn.pad_sequence(attention_masks_train, batch_first=True)\n",
    "labels_one_hot_train = torch.nn.functional.one_hot(train_labels, num_classes=3).float()\n",
    "\n",
    "input_ids_val = [x['input_ids'].squeeze(0) for x in tokenized_input_val]\n",
    "input_ids_val = torch.nn.utils.rnn.pad_sequence(input_ids_val, batch_first=True)\n",
    "attention_masks_val = [x['attention_mask'].squeeze(0) for x in tokenized_input_val]\n",
    "attention_masks_val = torch.nn.utils.rnn.pad_sequence(attention_masks_val, batch_first=True)\n",
    "labels_one_hot_val = torch.nn.functional.one_hot(val_labels, num_classes=3).float()\n",
    "\n",
    "tensor_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_one_hot_train)\n",
    "\n",
    "dataset = DictDataset(tensor_dataset)\n",
    "\n",
    "validation_tensor_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_one_hot_val)\n",
    "validation_dataset = DictDataset(validation_tensor_dataset)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=10,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=64,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    "    logging_steps=10,                \n",
    "    evaluation_strategy='steps',     \n",
    "    eval_steps=50,                   \n",
    "    save_strategy='epoch',           \n",
    "    save_steps=100,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer with the wrapped dataset\n",
    "trainer = Trainer(\n",
    "    model=model,                   \n",
    "    args=training_args,            \n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=validation_dataset\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7491518376579546, 0.7461999999999999, 0.7432060968848617)\n"
     ]
    }
   ],
   "source": [
    "# predict after training\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in validation_dataset:\n",
    "        batch_input_ids = batch['input_ids'].unsqueeze(0).to(device)\n",
    "        batch_attention_mask = batch['attention_mask'].unsqueeze(0).to(device)\n",
    "        outputs = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predictions.extend(predicted_classes)\n",
    "\n",
    "predictions = torch.stack(predictions)\n",
    "\n",
    "\n",
    "print(calc_f1_score(predictions, val_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
