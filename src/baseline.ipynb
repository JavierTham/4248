{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "from transformers import get_scheduler\n",
    "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_id = {\"entailment\": 0, \"neutral\": 1, \"contradiction\": 2}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "\n",
    "def renameColumns(df):\n",
    "    return df.rename(columns={'Sentence1': 'premise', 'Sentence2': 'hypothesis', 'Explanation_1': 'explanation'})\n",
    "\n",
    "def filterNan(df):\n",
    "    return df.dropna()\n",
    "\n",
    "def convert_to_tensors(df):\n",
    "    return torch.tensor(df.values)\n",
    "\n",
    "def encode_labels(df):\n",
    "    return df.apply(lambda x: int(label_to_id[x]))\n",
    "\n",
    "template = \"Given that {}, it is hypothesized that {}. {}.\"\n",
    "\n",
    "def tokenize(df, tokenizer):\n",
    "    tokenized_batch = []\n",
    "    for _, row in df.iterrows():\n",
    "        premise = row['premise'].lower()\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        hypothesis = row['hypothesis'].lower()\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        explanation = row['explanation'].lower()\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text = template.format(premise, hypothesis, explanation),\n",
    "            padding=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        tokenized_batch.append(encoded_dict)\n",
    "    return tokenized_batch\n",
    "\n",
    "def calc_f1_score(predicted_classes, actual_labels):\n",
    "    return f1_score(predicted_classes, actual_labels, average='weighted'), f1_score(predicted_classes, actual_labels, average='micro'), f1_score(predicted_classes, actual_labels, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=3)\n",
    "\n",
    "# change the model's classifier to a smaller one\n",
    "dense = nn.Linear(768, 256)\n",
    "out = nn.Linear(256, 3)\n",
    "model.classifier.dense = dense\n",
    "model.classifier.out_proj = out\n",
    "\n",
    "# freeze all the parameters in the base model\n",
    "for name, param in model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only train the classification head\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "premise_template = 'Given that {}, it is hypothesized that {}.'\n",
    "explanation_template = 'This is {} because {}.'\n",
    "\n",
    "class eSNLIDataset(Dataset):\n",
    "    def __init__(self, df, tokenizer, train=True):\n",
    "        self.df = df\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        example = self.df.iloc[idx,:]\n",
    "        premise = example[\"premise\"]\n",
    "        hypothesis = example[\"hypothesis\"]\n",
    "        explanation = example[\"explanation\"]\n",
    "\n",
    "        if premise[-1] in ['.', '!', '?']:\n",
    "            premise = premise[:-1]\n",
    "        if hypothesis[-1] in ['.', '!', '?']:\n",
    "            hypothesis = hypothesis[:-1]\n",
    "        if explanation[-1] in ['.', '!', '?']:\n",
    "            explanation = explanation[:-1]\n",
    "\n",
    "        premise = premise_template.format(premise, hypothesis)\n",
    "        explanation = explanation_template.format(tokenizer.mask_token, explanation)\n",
    "\n",
    "        if self.train:\n",
    "            label = example[\"gold_label\"]\n",
    "            return premise, explanation, label\n",
    "        \n",
    "        return premise, explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = pd.read_csv('../data/esnli_train_1.csv')\n",
    "df_train2 = pd.read_csv('../data/esnli_train_2.csv')\n",
    "df_train = pd.concat((df_train1, df_train2), axis=0)\n",
    "\n",
    "df_dev = pd.read_csv('../data/esnli_dev.csv')\n",
    "df_test = pd.read_csv('../data/esnli_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_renamed = renameColumns(df_train)\n",
    "df_train_cleaned = filterNan(df_train_renamed)\n",
    "df_train_cleaned.loc[:, \"gold_label\"] = encode_labels(df_train_cleaned[\"gold_label\"])\n",
    "df_train_final = df_train_cleaned.loc[:, [\"gold_label\", \"premise\", \"hypothesis\", \"explanation\"]]\n",
    "\n",
    "df_train_final = df_train_final.sample(n=5000, random_state=0).reset_index(drop=True)\n",
    "\n",
    "df_dev_renamed = renameColumns(df_dev)\n",
    "df_dev_cleaned = filterNan(df_dev_renamed)\n",
    "df_dev_cleaned.loc[:, \"gold_label\"] = encode_labels(df_dev_cleaned[\"gold_label\"])\n",
    "df_dev_final = df_dev_cleaned.loc[:, [\"gold_label\", \"premise\", \"hypothesis\", \"explanation\"]]\n",
    "\n",
    "df_test_renamed = renameColumns(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "train_batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = eSNLIDataset(df_train_final, tokenizer)\n",
    "dev_dataset = eSNLIDataset(df_dev_final, tokenizer, train=False)\n",
    "test_dataset = eSNLIDataset(df_test, tokenizer, train=False)\n",
    " \n",
    "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size)\n",
    "dev_dataloader = DataLoader(dev_dataset, batch_size=train_batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mac\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# for nvidia GPUs\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "num_training_steps = num_epochs * len(train_dataloader) # <- number of batches\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    ")\n",
    "criterion = CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45482562ace647fcb6767dac1af87874",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "y_true = []\n",
    "\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    for batch in train_dataloader:\n",
    "        premise, hypothesis, labels = batch\n",
    "\n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "        \n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.to(device)\n",
    "\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict after training\n",
    "model.to(device)\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "actual_labels = df_dev_final['gold_label'].astype(\"int\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dev_dataset:\n",
    "        premise, hypothesis = batch\n",
    "        \n",
    "        encoded_input = tokenizer(premise, hypothesis, return_tensors=\"pt\",padding=True, truncation=True).to(device)\n",
    "\n",
    "        outputs = model(**encoded_input)\n",
    "        logits = outputs.logits.cpu()\n",
    "\n",
    "        predicted_classes = torch.argmax(logits, dim=1)\n",
    "        predicted_classes = [pred.item() for pred in predicted_classes]\n",
    "        predictions.extend(predicted_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6079069044621613, 0.5073155862629547, 0.4096640935466172)\n"
     ]
    }
   ],
   "source": [
    "print(calc_f1_score(predictions, actual_labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs4248",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
